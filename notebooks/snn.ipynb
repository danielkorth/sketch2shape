{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siamese_ckpt_path = \"/home/borth/sketch2shape/logs/train_siamese/runs/2024-02-13_07-35-49/checkpoints/epoch_699.ckpt\"\n",
    "siamese_ckpt_path = \"/home/borth/sketch2shape/checkpoints/siamese.ckpt\"\n",
    "shape_view_id = 11\n",
    "shape_k = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import SiameseTransform\n",
    "import hydra\n",
    "from lib.utils import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from lib.visualize.image import image_grid\n",
    "\n",
    "\n",
    "def transform(normal):\n",
    "    _transform = SiameseTransform()\n",
    "    return _transform(normal).to(\"cuda\")\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "def siamese_loss(emb_1, emb_2):\n",
    "    return 1 - cosine_similarity(emb_1, emb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"optimize_sketch\", [\"+data=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "\n",
    "cfg.siamese_ckpt_path = siamese_ckpt_path\n",
    "cfg.model.shape_k = shape_k\n",
    "cfg.model.shape_view_id = shape_view_id\n",
    "cfg.model.shape_init = True\n",
    "cfg.model.obj_id = metainfo.obj_ids[3]\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "\n",
    "sketch_3 = np.asarray(metainfo.load_image(3, 11, 0))\n",
    "sketch_5 = np.asarray(metainfo.load_image(5, 11, 0))\n",
    "model.latent = model.deepsdf.lat_vecs.weight[3]\n",
    "rendered_normal_3 = model.capture_camera_frame().detach().cpu().numpy()\n",
    "\n",
    "rendered_normal_3_emb = model.siamese(transform(rendered_normal_3)[None, ...])\n",
    "sketch_3_emb = model.siamese(transform(sketch_3)[None, ...])\n",
    "sketch_5_emb = model.siamese(transform(sketch_5)[None, ...])\n",
    "\n",
    "print(f\"{siamese_loss(sketch_3_emb, rendered_normal_3_emb)=}\")\n",
    "plot_images([sketch_3, rendered_normal_3])\n",
    "\n",
    "print(f\"{siamese_loss(sketch_5_emb, rendered_normal_3_emb)=}\")\n",
    "plot_images([sketch_5, rendered_normal_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "start_latent_ids = [3385, 2801, 1962, 1058, 782, 1328]  # couch nn\n",
    "# start_latent_ids = [3, 0, 1, 2, 4, 5, 6] # couch far\n",
    "# start_latent_ids = [3, 0, 1, 2, 4, 5, 6] # couch far\n",
    "# start_latent_ids = [0, 5]  # couch far\n",
    "end_latent_id = 3\n",
    "sketch_view = 11\n",
    "traversal_steps = 20\n",
    "image_skip = 4\n",
    "azims = [40]\n",
    "elevs = [-30]\n",
    "\n",
    "# fetch and encode the sketch\n",
    "sketch = metainfo.load_image(end_latent_id, sketch_view, 0)\n",
    "sketch_emb = model.siamese(transform(sketch)[None, ...])\n",
    "\n",
    "image_trajectories = []\n",
    "loss_trajectories = []\n",
    "for idx, start_latent_id in enumerate(start_latent_ids):\n",
    "    image_trajectory = [sketch]\n",
    "    loss_trajectory = []\n",
    "    desc = f\"{idx+1}/{len(start_latent_ids)}\"\n",
    "    for t in tqdm(np.linspace(1, 0, traversal_steps), desc=desc):\n",
    "        start_latent = model.deepsdf.lat_vecs.weight[start_latent_id]\n",
    "        end_latent = model.deepsdf.lat_vecs.weight[end_latent_id]\n",
    "        model.latent = t * start_latent + (1 - t) * end_latent\n",
    "\n",
    "        # calculate the mean loss from all the views\n",
    "        loss = []\n",
    "        for azim in azims:\n",
    "            for elev in elevs:\n",
    "                model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "                rendered_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "                rendered_normal_emb = model.siamese(\n",
    "                    transform(rendered_normal)[None, ...]\n",
    "                )\n",
    "                snn_loss = siamese_loss(sketch_emb, rendered_normal_emb)\n",
    "                loss.append(snn_loss)\n",
    "                image_trajectory.append(rendered_normal)\n",
    "        loss = torch.stack(loss).mean()\n",
    "\n",
    "        # add the loss to the trajectory\n",
    "        loss_trajectory.append(loss.detach().cpu().numpy())\n",
    "    loss_trajectories.append(loss_trajectory)\n",
    "    image_trajectories.append(image_trajectory)\n",
    "\n",
    "# plot the images\n",
    "for image_trajectory in image_trajectories:\n",
    "    trajectory = []\n",
    "    for idx, img in enumerate(image_trajectory):\n",
    "        if idx == 0 or (idx - 1) % image_skip == 0:\n",
    "            trajectory.append(img)\n",
    "    plot_images(trajectory, size=16)\n",
    "\n",
    "# plot the loss curves\n",
    "for obj_id, loss_trajectory in zip(start_latent_ids, loss_trajectories):\n",
    "    plt.plot(\n",
    "        np.linspace(0, 1, traversal_steps),\n",
    "        np.stack(loss_trajectory),\n",
    "        label=obj_id,\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"siamese_loss\")\n",
    "plt.xlabel(\"traversal_steps\")\n",
    "plt.show()\n",
    "\n",
    "x = np.linspace(0, 1, 20)\n",
    "mean = np.stack(loss_trajectories).mean(0)\n",
    "std = np.stack(loss_trajectories).std(0)\n",
    "plt.plot(x, mean)\n",
    "plt.fill_between(x, (mean - std), (mean + std), color=\"b\", alpha=0.1)\n",
    "plt.ylabel(\"siamese_loss\")\n",
    "plt.xlabel(\"traversal_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = model.deepsdf.lat_vecs.weight[0]\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "normal_emb = model.siamese(transform(normal)[None, ...])\n",
    "print(f\"{siamese_loss(sketch_3_emb, normal_emb)=}\")\n",
    "plot_images([sketch_3, normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tensor(2549, device='cuda:0') tensor(0.6049, device='cuda:0')\n",
    "tensor(1328, device='cuda:0') tensor(1.4948, device='cuda:0')\n",
    "tensor(1898, device='cuda:0') tensor(0.6908, device='cuda:0')\n",
    "tensor(962, device='cuda:0') tensor(0.6423, device='cuda:0')\n",
    "tensor(535, device='cuda:0') tensor(0.8771, device='cuda:0')\n",
    "tensor(755, device='cuda:0') tensor(0.4972, device='cuda:0')\n",
    "tensor(2432, device='cuda:0') tensor(1.8280, device='cuda:0')\n",
    "tensor(3089, device='cuda:0') tensor(0.9243, device='cuda:0')\n",
    "tensor(3885, device='cuda:0') tensor(1.6862, device='cuda:0')\n",
    "tensor(1447, device='cuda:0') tensor(1.0207, device='cuda:0')\n",
    "tensor(3195, device='cuda:0') tensor(0.8885, device='cuda:0')\n",
    "tensor(2207, device='cuda:0') tensor(0.7391, device='cuda:0')\n",
    "tensor(277, device='cuda:0') tensor(0.7135, device='cuda:0')\n",
    "tensor(1058, device='cuda:0') tensor(0.6626, device='cuda:0')\n",
    "tensor(841, device='cuda:0') tensor(1.0481, device='cuda:0')\n",
    "tensor(1637, device='cuda:0') tensor(0.6819, device='cuda:0')\n",
    "\"\"\"\n",
    "model.latent = model.deepsdf.lat_vecs.weight[3885]\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images(normal)\n",
    "\n",
    "mean = model.shape_latents.mean(0)\n",
    "std = model.shape_latents.std(0)\n",
    "\n",
    "good_latents = []\n",
    "for i in range(4096):\n",
    "    latent = model.deepsdf.lat_vecs.weight[i]\n",
    "    reg_loss = ((mean - latent) / std).pow(2).mean()\n",
    "    if reg_loss <= 1.0 and i != 3:\n",
    "        good_latents.append(latent)\n",
    "\n",
    "for i in range(5):\n",
    "    latent = model.deepsdf.lat_vecs.weight[i]\n",
    "    reg_loss = ((mean - latent) / std).pow(2).mean()\n",
    "    print(\"init\", i, reg_loss)\n",
    "\n",
    "mean = torch.stack(good_latents).mean(0)\n",
    "std = torch.stack(good_latents).std(0)\n",
    "for i in range(5):\n",
    "    latent = model.deepsdf.lat_vecs.weight[i]\n",
    "    reg_loss = ((mean - latent) / std).pow(2).mean()\n",
    "    print(\"good\", i, reg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4096):\n",
    "    latent = model.deepsdf.lat_vecs.weight[i]\n",
    "    reg_loss = ((mean - latent) / std).pow(2).mean()\n",
    "    if reg_loss <= 1.0:\n",
    "        print(i, reg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = model.deepsdf.lat_vecs.weight[1962]\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images(normal)\n",
    "# mean = model.shape_latents.mean(0)\n",
    "# std = model.shape_latents.std(0)\n",
    "# mean = torch.stack(good_latents).mean(0)\n",
    "# std = torch.stack(good_latents).std(0)\n",
    "\n",
    "((mean - latent) / std).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Latent Code (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_latent_id = 3385\n",
    "end_latent_id = 3\n",
    "optim_steps = 10\n",
    "\n",
    "t = torch.tensor(1.0, dtype=torch.float32).to(\"cuda\")\n",
    "t.requires_grad = True\n",
    "start_latent = model.deepsdf.lat_vecs.weight[start_latent_id]\n",
    "start_latent.requires_grad = True\n",
    "end_latent = model.deepsdf.lat_vecs.weight[end_latent_id]\n",
    "end_latent.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam([t], lr=0.1)\n",
    "\n",
    "sketch = metainfo.load_image(end_latent_id, 11, 0)\n",
    "sketch_emb = model.siamese(transform(sketch)[None, ...])\n",
    "\n",
    "image_trajectory = [np.asarray(sketch)]\n",
    "loss_trajectory = []\n",
    "reg_loss_trajectory = []\n",
    "t_trajectory = []\n",
    "with tqdm(total=optim_steps) as pbar:\n",
    "    for step in range(optim_steps):\n",
    "        model.latent = t * start_latent + (1 - t) * end_latent\n",
    "        points, surface_mask = model.deepsdf.sphere_tracing(\n",
    "            latent=model.latent,\n",
    "            points=model.deepsdf.camera_points,\n",
    "            rays=model.deepsdf.camera_rays,\n",
    "            mask=model.deepsdf.camera_mask,\n",
    "        )\n",
    "        rendered_normal = model.deepsdf.render_normals(\n",
    "            latent=model.latent,\n",
    "            points=points,\n",
    "            mask=surface_mask,\n",
    "        )  # (H, W, 3)\n",
    "        normal = model.deepsdf.normal_to_siamese(rendered_normal)  # (1, 3, H, W)\n",
    "        normal_emb = model.siamese(normal)  # (1, D)\n",
    "\n",
    "        snn_loss = siamese_loss(sketch_emb, normal_emb)\n",
    "\n",
    "        std = model.shape_latents.std(0)\n",
    "        mean = model.shape_latents.mean(0)\n",
    "        reg_loss = ((model.latent.clone() - mean) / std).pow(2)\n",
    "        reg_loss_trajectory.append(reg_loss.mean().item())\n",
    "\n",
    "        loss_trajectory.append(snn_loss.item())        \n",
    "        t_trajectory.append(t.item())        \n",
    "        image_trajectory.append(rendered_normal.detach().cpu().numpy())\n",
    "\n",
    "        snn_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pbar.set_postfix({\"t\": t.item()})\n",
    "        pbar.update(1)\n",
    "\n",
    "# images\n",
    "plot_images(image_trajectory, size=16)\n",
    "\n",
    "# loss\n",
    "plt.plot(\n",
    "    np.linspace(0, 1, optim_steps),\n",
    "    np.stack(loss_trajectory),\n",
    "    label=obj_id,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"siamese_loss\")\n",
    "plt.xlabel(\"optim_steps\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(\n",
    "    np.linspace(0, 1, optim_steps),\n",
    "    np.stack(reg_loss_trajectory),\n",
    "    label=obj_id,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"reg_loss\")\n",
    "plt.xlabel(\"optim_steps\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(\n",
    "    np.linspace(0, 1, optim_steps),\n",
    "    np.stack(t_trajectory),\n",
    "    label=obj_id,\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"t\")\n",
    "plt.xlabel(\"optim_steps\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
