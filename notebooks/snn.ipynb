{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import SiameseTransform\n",
    "import hydra\n",
    "from lib.utils import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from lib.visualize.image import image_grid\n",
    "from lightning import Trainer\n",
    "\n",
    "def transform(normal):\n",
    "    _transform = SiameseTransform()\n",
    "    return _transform(normal).to(\"cuda\")\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        fig, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "def siamese_loss(emb_1, emb_2):\n",
    "    return 1 - cosine_similarity(emb_1, emb_2)\n",
    "\n",
    "\n",
    "cfg = load_config(\"traverse_latent\", [\"+experiment/traverse_latent=siamese_train_train_1\"])\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "metainfo = MetaInfo(\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "\n",
    "gt_image_1 = np.asarray(metainfo.load_image(3, 11, 0))\n",
    "gt_image_2 = np.asarray(metainfo.load_image(3, 11, 1))\n",
    "wrong_image_1 = np.asarray(metainfo.load_image(5, 11, 1))\n",
    "\n",
    "model.latent = model.latent_end\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "\n",
    "print(\"sketch\", \"gt_normal\", \"deepsdf_normal\", \"wrong_image_1\")\n",
    "plot_images([gt_image_1, gt_image_2, normal, wrong_image_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = model.deepsdf.lat_vecs.weight[5].clone()\n",
    "std1 = torch.stack(lats).std(0)\n",
    "mean1 = torch.stack(lats).mean(0)\n",
    "x1 = ((latent - mean1) / std1)\n",
    "\n",
    "std2 = model.deepsdf.lat_vecs.weight.std(0)\n",
    "mean2 = model.deepsdf.lat_vecs.weight.mean(0)\n",
    "x2 = ((latent - mean2) / std2).pow(2)\n",
    "# sorted(x)[::-1][:40]\n",
    "# sorted(x)\n",
    "plt.plot(x1.detach().cpu().numpy())\n",
    "plt.plot(x2.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = model.deepsdf.lat_vecs.weight[5].clone()\n",
    "mean1 = torch.stack(lats).mean(0)\n",
    "grad_direction = (grad / torch.abs(grad).max()).detach().cpu().numpy()\n",
    "# latent_direction = ((mean1-latent)/torch.abs((mean1-latent)).max()).detach().cpu().numpy()\n",
    "plt.plot(np.sign(x1.detach().cpu().numpy()) * np.sign(grad_direction))\n",
    "# plt.plot(np.sign(grad_direction))\n",
    "# plt.plot(latent_direction)\n",
    "# plt.plot(grad_direction - latent_direction)\n",
    "pp = np.sign(x1.detach().cpu().numpy()) * np.sign(grad_direction)\n",
    "high_diff_latents = reversed(torch.argsort(x1))\n",
    "for i in range(10):\n",
    "    print(pp[high_diff_latents[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.latent = model.deepsdf.lat_vecs.weight[5].clone()\n",
    "model.latent = torch.stack(lats).mean(0).clone()\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images(normal)\n",
    "\n",
    "std1 = torch.stack(lats).std(0)\n",
    "mean1 = torch.stack(lats).mean(0)\n",
    "x1 = ((latent - mean1) / std1).pow(2)\n",
    "\n",
    "images = []\n",
    "high_diff_latents = reversed(torch.argsort(x1))\n",
    "# high_diff_latents = torch.argsort(x1)\n",
    "for idx, latent_idx in enumerate(high_diff_latents):\n",
    "    model.latent[latent_idx] = mean1[latent_idx]\n",
    "    normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    images.append(normal)\n",
    "    if idx > 16:\n",
    "        break\n",
    "plot_images(images, size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = metainfo.load_image(3, 11, 0)\n",
    "sketch_emb = model.siamese(transform(sketch)[None, ...])\n",
    "\n",
    "model.latent = model.deepsdf.lat_vecs.weight[5].clone()\n",
    "model.latent.requires_grad = True\n",
    "points, surface_mask = model.deepsdf.sphere_tracing(\n",
    "    latent=model.latent,\n",
    "    points=model.deepsdf.camera_points,\n",
    "    rays=model.deepsdf.camera_rays,\n",
    "    mask=model.deepsdf.camera_mask,\n",
    ")\n",
    "rendered_normal = model.deepsdf.render_normals(\n",
    "    latent=model.latent,\n",
    "    points=points,\n",
    "    mask=surface_mask,\n",
    ")  # (H, W, 3)\n",
    "normal = model.deepsdf.normal_to_siamese(rendered_normal)  # (1, 3, H, W)\n",
    "normal_emb = model.siamese(normal)  # (1, D)\n",
    "\n",
    "snn_loss = siamese_loss(sketch_emb, normal_emb)\n",
    "\n",
    "(grad,) = torch.autograd.grad(\n",
    "    outputs=snn_loss,\n",
    "    inputs=model.latent,\n",
    "    grad_outputs=torch.ones_like(snn_loss)\n",
    ")\n",
    "plt.plot(grad.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = model.deepsdf.lat_vecs.weight[5]\n",
    "# std = torch.stack(lats).std(0)\n",
    "# mean = torch.stack(lats).mean(0)\n",
    "std = model.deepsdf.lat_vecs.weight.std(0)\n",
    "mean = model.deepsdf.lat_vecs.weight.mean(0)\n",
    "x = ((model.deepsdf.lat_vecs.weight[3] - mean) / std).pow(2)\n",
    "# # sorted(x)[::-1][:40]\n",
    "x.mean()\n",
    "# # sorted(x)\n",
    "# plt.plot(x.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN L2-Dist Sketch - Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = model.latent_end\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "emb_1 = model.siamese(transform(gt_image_1)[None, ...])\n",
    "emb_2 = model.siamese(transform(gt_image_2)[None, ...])\n",
    "print(siamese_loss(emb_1, emb_2))\n",
    "plot_images([gt_image_1, gt_image_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN L2-Dist Sketch - DeepSDF Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = model.latent_end\n",
    "normal = model.capture_camera_frame()\n",
    "normal_input = model.deepsdf.normal_to_siamese(normal)\n",
    "\n",
    "emb_1 = model.siamese(transform(gt_image_1)[None, ...])\n",
    "emb_2 = model.siamese(normal_input)\n",
    "print(siamese_loss(emb_1, emb_2))\n",
    "plot_images([gt_image_1, normal.detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN L2-Dist Normal - DeepSDF Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = model.latent_end\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "emb_1 = model.siamese(transform(gt_image_2)[None, ...])\n",
    "emb_2 = model.siamese(transform(normal)[None, ...])\n",
    "print(siamese_loss(emb_1, emb_2))\n",
    "plot_images([gt_image_2, normal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN L2-Dist Wrong - DeepSDF Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = model.latent_end\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "emb_1 = model.siamese(transform(wrong_image_1)[None, ...])\n",
    "emb_2 = model.siamese(transform(normal)[None, ...])\n",
    "print(siamese_loss(emb_1, emb_2))\n",
    "plot_images([wrong_image_1, normal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN L2-Dist GT Normal All Views (90) - DeepSDF Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "loss = []\n",
    "emb_normal = model.siamese(transform(normal)[None, ...])\n",
    "\n",
    "for i in tqdm(range(90), total=90):\n",
    "    gt_image = np.asarray(metainfo.load_image(3, i, 1))\n",
    "    emb_image = model.siamese(transform(gt_image)[None, ...])\n",
    "    _loss = siamese_loss(emb_normal, emb_image) \n",
    "    loss.append(_loss)\n",
    "loss = torch.concatenate(loss)\n",
    "print(f\"{loss.mean()=}\")\n",
    "print(f\"{loss.min()=}\")\n",
    "print(f\"{loss.max()=}\")\n",
    "plot_images([gt_image, normal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15-NN Latent Code Shape(3) Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the top 15 latent codes and then print the SNN loss\n",
    "model.latent_end = model.deepsdf.lat_vecs.weight[0] \n",
    "model.latent = model.deepsdf.lat_vecs.weight[0]\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "emb_normal = model.siamese(transform(normal)[None, ...])\n",
    "lats = []\n",
    "for _i in range(10):\n",
    "    latent = model.latent_end\n",
    "    dist = torch.abs(model.deepsdf.lat_vecs.weight - latent[None, ...]).mean(-1)\n",
    "    idx = torch.argsort(dist, descending=False)\n",
    "    model.latent = model.deepsdf.lat_vecs.weight[idx[_i]]\n",
    "    lats.append(model.latent)\n",
    "    metainfo.label_to_obj_id(idx[_i].item()), idx[_i], dist[idx[_i]]\n",
    "\n",
    "    loss = []\n",
    "    for i in range(90):\n",
    "        gt_image = np.asarray(metainfo.load_image(idx[_i].item(), i, 0))\n",
    "        emb_image = model.siamese(transform(gt_image)[None, ...])\n",
    "        _loss = siamese_loss(emb_normal, emb_image) \n",
    "        loss.append(_loss)\n",
    "    loss = torch.concatenate(loss)\n",
    "\n",
    "    print(idx[_i], loss.mean())\n",
    "    _n = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    plot_images(_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argsort(dist, descending=False)\n",
    "ids = list(idx[1:1+128].cpu().numpy())\n",
    "model.latent = model.deepsdf.lat_vecs.weight[ids].mean(0)\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.latent = torch.stack(lats).mean(0)\n",
    "normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images([normal, gt_image_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "# start_latent_ids = [3, 3385, 2801, 1962, 1058, 782, 1328]  # couch nn\n",
    "# start_latent_ids = [3, 0, 1, 2, 4, 5, 6] # couch far\n",
    "# start_latent_ids = [3, 0, 1, 2, 4, 5, 6] # couch far\n",
    "start_latent_ids = [0] # couch far\n",
    "# start_latent_ids = list(range(128))\n",
    "end_latent_id = 0\n",
    "sketch_view = 11\n",
    "traversal_steps = 20\n",
    "image_skip = 4\n",
    "azims = [40]\n",
    "elevs = [-30]\n",
    "\n",
    "# fetch and encode the sketch\n",
    "sketch = metainfo.load_image(end_latent_id, sketch_view, 0)\n",
    "sketch_emb = model.siamese(transform(sketch)[None, ...])\n",
    "\n",
    "image_trajectories = []\n",
    "loss_trajectories = []\n",
    "for idx, start_latent_id in enumerate(start_latent_ids):\n",
    "    image_trajectory = [sketch]\n",
    "    loss_trajectory = []\n",
    "    desc = f\"{idx+1}/{len(start_latent_ids)}\"\n",
    "    for t in tqdm(np.linspace(1, 0, traversal_steps), desc=desc):\n",
    "        start_latent = model.deepsdf.lat_vecs.weight[start_latent_id]\n",
    "        start_latent = model.deepsdf.lat_vecs.weight[ids].mean(0)\n",
    "        end_latent = model.deepsdf.lat_vecs.weight[end_latent_id]\n",
    "        model.latent = t * start_latent + (1 - t) * end_latent\n",
    "\n",
    "        # calculate the mean loss from all the views \n",
    "        loss = []\n",
    "        for azim in azims:\n",
    "            for elev in elevs:\n",
    "                model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "                rendered_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "                rendered_normal_emb = model.siamese(transform(rendered_normal)[None, ...])\n",
    "                snn_loss = siamese_loss(sketch_emb, rendered_normal_emb)\n",
    "                loss.append(snn_loss)\n",
    "                image_trajectory.append(rendered_normal)\n",
    "        loss = torch.stack(loss).mean()\n",
    "\n",
    "        # add the loss to the trajectory\n",
    "        loss_trajectory.append(loss.detach().cpu().numpy())\n",
    "    loss_trajectories.append(loss_trajectory)\n",
    "    image_trajectories.append(image_trajectory)\n",
    "\n",
    "# # plot the images\n",
    "# for image_trajectory in image_trajectories:\n",
    "#     trajectory = [] \n",
    "#     for idx, img in enumerate(image_trajectory):\n",
    "#         if idx == 0 or (idx-1) % image_skip == 0:\n",
    "#             trajectory.append(img)\n",
    "#     plot_images(trajectory, size=16)\n",
    "\n",
    "# # plot the loss curves\n",
    "# for obj_id, loss_trajectory in zip(start_latent_ids, loss_trajectories):\n",
    "#     plt.plot(np.linspace(0, 1, traversal_steps), np.stack(loss_trajectory), label=obj_id)\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "# plt.ylabel(\"siamese_loss\")\n",
    "# plt.xlabel(\"traversal_steps\")\n",
    "# plt.show()\n",
    "\n",
    "x = np.linspace(0, 1, 20)\n",
    "mean = np.stack(loss_trajectories).mean(0)\n",
    "std = np.stack(loss_trajectories).std(0)\n",
    "plt.plot(x, mean)\n",
    "plt.fill_between(x, (mean-std), (mean+std), color='b', alpha=0.1)\n",
    "plt.ylabel(\"siamese_loss\")\n",
    "plt.xlabel(\"traversal_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# settings\n",
    "# normal_obj_id = 1962\n",
    "normal_obj_id = 3\n",
    "# normal_obj_id = 1328\n",
    "sketch_obj_id = 3\n",
    "sketch_view = 11\n",
    "# azims = cfg.data.preprocess_siamese.azims \n",
    "# elevs = cfg.data.preprocess_siamese.elevs\n",
    "azims = [0, 40, 80, 120, 160, 200, 240, 280, 320]\n",
    "elevs = [-50, -30, -10, 10]\n",
    "\n",
    "# fetch and encode the sketch\n",
    "sketch = metainfo.load_image(sketch_obj_id, sketch_view, 0)\n",
    "sketch_emb = model.siamese(transform(sketch)[None, ...])\n",
    "\n",
    "image_trajectory = []\n",
    "model.latent =  model.deepsdf.lat_vecs.weight[normal_obj_id]\n",
    "# calculate the mean loss from all the views \n",
    "loss = []\n",
    "for elev in tqdm(elevs):\n",
    "    for azim in azims:\n",
    "        model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "        rendered_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "        rendered_normal_emb = model.siamese(transform(rendered_normal)[None, ...])\n",
    "        snn_loss = siamese_loss(sketch_emb, rendered_normal_emb)\n",
    "        loss.append(snn_loss)\n",
    "        image_trajectory.append(rendered_normal)\n",
    "loss = torch.stack(loss)\n",
    "\n",
    "# visualize the grid\n",
    "image_grid(image_trajectory, cols=len(azims), rows=len(elevs))\n",
    "plt.show()\n",
    "\n",
    "# visusalize the loss\n",
    "loss = loss.reshape(len(elevs), len(azims))\n",
    "plt.imshow(loss.detach().cpu().numpy(), vmin=0, vmax=1.0)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visusalize the loss\n",
    "loss = loss.reshape(len(elevs), len(azims))\n",
    "plt.imshow(loss.detach().cpu().numpy(), vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Latent Code from 15-NN Latent Code Shape(3) Prior -> Mean of Latent Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in np.linspace(2, 0, 10):\n",
    "    noise = torch.rand_like(model.latent_end) * torch.stack(lats).std(0) * s\n",
    "    model.latent = torch.stack(lats).mean(0) + noise\n",
    "    normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    emb_1 = model.siamese(transform(gt_image_1)[None, ...])\n",
    "    emb_2 = model.siamese(transform(normal)[None, ...])\n",
    "    print(torch.norm(emb_1 - emb_2, dim=-1))\n",
    "    plot_images(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN Retrieval Top 10 Latent Code Based on Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# encode the images\n",
    "embs = []\n",
    "for i in tqdm(range(4096)):\n",
    "    img = metainfo.load_image(i, 11, 0) # load the normals from a good view\n",
    "    emb = model.siamese(transform(img)[None, ...])\n",
    "    embs.append(emb)\n",
    "embs = torch.stack(embs).squeeze(1)\n",
    "\n",
    "img = metainfo.load_image(3, 11, 0) # load the normals from a good view\n",
    "query_emb= model.siamese(transform(img)[None, ...])\n",
    "\n",
    "# get the top index in SNN space\n",
    "k = 10\n",
    "loss =[]\n",
    "for emb in tqdm(embs):\n",
    "    loss.append(siamese_loss(emb, query_emb))\n",
    "loss = torch.concatenate(loss)\n",
    "idx = torch.argsort(loss)[:k]  # (Q, k)\n",
    "top_loss, top_idx = loss.take(idx).detach().cpu().numpy(), idx.detach().cpu().numpy()\n",
    "\n",
    "snn_lats = []\n",
    "for loss, i in zip(top_loss,top_idx):\n",
    "    model.latent = model.deepsdf.lat_vecs.weight[i]\n",
    "    _n = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    snn_lats.append(model.latent)\n",
    "    print(loss, i)\n",
    "    plot_images(_n, size=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in np.linspace(2, 0, 10):\n",
    "    noise = torch.rand_like(model.latent_end) * torch.stack(snn_lats).std(0) * s\n",
    "    model.latent = torch.stack(snn_lats).mean(0) + noise\n",
    "    normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    emb_1 = model.siamese(transform(gt_image_1)[None, ...])\n",
    "    emb_2 = model.siamese(transform(normal)[None, ...])\n",
    "    print(torch.norm(emb_1 - emb_2, dim=-1))\n",
    "    plot_images(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_id = 4192 # show \n",
    "val_id = 4193\n",
    "val_sketch = metainfo.load_image(val_id, 11, 0) # load the normals from a good view\n",
    "val_normal = metainfo.load_image(val_id, 11, 1) # load the normals from a good view\n",
    "emb_1 = model.siamese(transform(val_sketch)[None, ...])\n",
    "emb_2 = model.siamese(transform(val_normal)[None, ...])\n",
    "print(torch.norm(emb_1 - emb_2, dim=-1))\n",
    "plot_images([val_sketch, val_normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_emb= model.siamese(transform(val_sketch)[None, ...])\n",
    "\n",
    "# get the top index in SNN space\n",
    "k = 10\n",
    "sx = torch.sum(query_emb**2, dim=-1, keepdim=True)\n",
    "sy = torch.sum(embs**2, dim=-1, keepdim=True)\n",
    "dist = torch.sqrt(-2 * (query_emb @ embs.T) + sx + sy.T)  # (Q, I)\n",
    "dist = dist.nan_to_num(0)\n",
    "idx = torch.argsort(dist)[:, :k]  # (Q, k)\n",
    "top_dist, top_idx = dist.take(idx).detach().cpu().numpy(), idx.detach().cpu().numpy()\n",
    "\n",
    "val_lats = []\n",
    "val_weights = []\n",
    "for i in top_idx.flatten():\n",
    "    model.latent = model.deepsdf.lat_vecs.weight[i]\n",
    "    _n = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    val_lats.append(model.latent)\n",
    "    emb_1 = model.siamese(transform(val_sketch)[None, ...])\n",
    "    emb_2 = model.siamese(transform(_n)[None, ...])\n",
    "    weight = torch.norm(emb_1 - emb_2, dim=-1)\n",
    "    val_weights.append(weight)\n",
    "    print(weight)\n",
    "    plot_images(_n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in np.linspace(2, 0, 10):\n",
    "    noise = torch.rand_like(model.latent_end) * torch.stack(val_lats).std(0) * s\n",
    "    model.latent = torch.stack(val_lats).mean(0) + noise\n",
    "    normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    emb_1 = model.siamese(transform(gt_image_1)[None, ...])\n",
    "    emb_2 = model.siamese(transform(normal)[None, ...])\n",
    "    print(torch.norm(emb_1 - emb_2, dim=-1))\n",
    "    plot_images(normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Latent Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 20, 2):\n",
    "    w = torch.exp(-i * torch.concatenate(val_weights))\n",
    "    w = w / w.sum()\n",
    "    print(w)\n",
    "    model.latent = (torch.stack(val_lats) * w[..., None]).sum(0)\n",
    "    normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "    emb_1 = model.siamese(transform(val_normal)[None, ...])\n",
    "    emb_2 = model.siamese(transform(normal)[None, ...])\n",
    "    print(torch.norm(emb_1 - emb_2, dim=-1))\n",
    "    plot_images([val_sketch, normal, val_normal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.scheduler import Coarse2FineScheduler\n",
    "scheduler = Coarse2FineScheduler(resolution=256, milestones=[1, 2])\n",
    "scheduler.current_epoch = 0\n",
    "image = scheduler.downsample(transform(gt_image_2), reducer=\"avg\")\n",
    "image = model.normal_to_image(image, resolution=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
