{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lib.data.transforms import BaseTransform, DilateSketch, SketchTransform\n",
    "from torchvision.transforms import v2\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.functional import l1_loss\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def to_sketch(img):\n",
    "    img = cv.Canny(\n",
    "        (img * 255).astype(np.uint8),\n",
    "        100,\n",
    "        150,\n",
    "        L2gradient=True,\n",
    "        apertureSize=3,\n",
    "    )\n",
    "    img = cv.bitwise_not(img)\n",
    "    return np.stack([img, img, img], axis=-1).astype(np.float32) / 255\n",
    "\n",
    "\n",
    "def plot_images_np(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image.detach().cpu().numpy())\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images.detach().cpu().numpy())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "sketch_transform = SketchTransform(kernel_size=3, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traversal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.prior_obj_id = metainfo.obj_ids[0]\n",
    "cfg.model.prior_mode = 0\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "source_id = 0\n",
    "sketch = metainfo.load_image(source_id, 34, 0)\n",
    "\n",
    "# for i in torch.randint(4096, (100,)):\n",
    "for i in torch.randint(4096, (10,)):\n",
    "    t = torch.normal(torch.tensor(0.25), torch.tensor(0.1))\n",
    "    t = torch.clamp(t, 0.0, 0.5)\n",
    "    azim = 30\n",
    "    elev = -20\n",
    "    model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "    target_id = i\n",
    "\n",
    "    source_latent = model.deepsdf.lat_vecs.weight[source_id]\n",
    "    model.latent = source_latent\n",
    "    source_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "\n",
    "    target_latent = model.deepsdf.lat_vecs.weight[target_id]\n",
    "    model.latent = target_latent\n",
    "    target_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "\n",
    "    interpolated_latent = (1 - t) * source_latent + t * target_latent\n",
    "    model.latent = interpolated_latent\n",
    "    interpolated_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "\n",
    "    plot_images_np(\n",
    "        [\n",
    "            sketch_transform(sketch).permute(1, 2, 0),\n",
    "            interpolated_normal\n",
    "        ],\n",
    "        size=8,\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Silhouette Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_label = 4168  # 10, 4112, (4117), 12, 13, 4152\n",
    "azim = 30\n",
    "elev = -10\n",
    "\n",
    "# create sketch\n",
    "img = metainfo.load_image(obj_label, 11, 0)\n",
    "transforms = [v2.Resize((256, 256)), ToSketch(), DilateSketch(kernel_size=3)]\n",
    "to_image = BaseTransform(normalize=False, transforms=transforms)\n",
    "sketch = to_image(img).permute(1, 2, 0)\n",
    "\n",
    "# setup model\n",
    "cfg.model.prior_obj_id = metainfo.obj_ids[obj_label]\n",
    "# cfg.model.loss_ckpt_path = \"/home/borth/sketch2shape/checkpoints/latent_siamese_sketch_grayscale_latent_256.ckpt\"\n",
    "cfg.model.loss_ckpt_path = (\n",
    "    \"/home/borth/sketch2shape/temp/old/latent_siamese_sketch_grayscale_latent_256.ckpt\"\n",
    ")\n",
    "cfg.model.latent_init = \"latent\"\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "model.deepsdf.create_camera(azim=azim, elev=elev)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    points, surface_mask = model.deepsdf.sphere_tracing(\n",
    "        latent=model.latent,\n",
    "        points=model.deepsdf.camera_points,\n",
    "        mask=model.deepsdf.camera_mask,\n",
    "        rays=model.deepsdf.camera_rays,\n",
    "    )\n",
    "    normals = model.deepsdf.render_normals(\n",
    "        points=points,\n",
    "        latent=model.latent,\n",
    "        mask=surface_mask,\n",
    "    )\n",
    "    grayscale = model.deepsdf.render_grayscale(\n",
    "        points=points,\n",
    "        latent=model.latent,\n",
    "        mask=surface_mask,\n",
    "    )\n",
    "    # grayscale = model.deepsdf.normals_to_grayscales(normals)\n",
    "    silhouette = model.deepsdf.render_silhouette(\n",
    "        normals=normals,\n",
    "        points=points,\n",
    "        latent=model.latent,\n",
    "        proj_blur_eps=0.7,\n",
    "        weight_blur_kernal_size=9,\n",
    "        weight_blur_sigma=9.0,\n",
    "    )\n",
    "plot_images(\n",
    "    [\n",
    "        sketch,\n",
    "        grayscale,\n",
    "        normals,\n",
    "        silhouette[\"base_silhouette\"],\n",
    "        silhouette[\"min_sdf\"],\n",
    "        silhouette[\"extra_silhouette\"],\n",
    "        silhouette[\"proj_silhouette\"],\n",
    "        silhouette[\"proj_blur_silhouette\"],\n",
    "        silhouette[\"base_blur_silhouette\"],\n",
    "        silhouette[\"weighted_silhouette\"],\n",
    "        silhouette[\"final_silhouette\"],\n",
    "    ],\n",
    "    size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Hand Drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
