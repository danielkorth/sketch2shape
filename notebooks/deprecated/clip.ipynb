{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel, CLIPImageProcessor\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "image = Image.open(\"/home/borth/sketch2shape/data/siamese_chair_medium/1a74a83fa6d24b3cacd67ce2c72c02e/images/00000.jpg\")\n",
    "\n",
    "inputs = processor(text=[\"\"], images=[image, image], return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7172)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.data[\"pixel_values\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPOutput(loss=None, logits_per_image=tensor([[16.2034],\n",
       "        [16.2034]], grad_fn=<TBackward0>), logits_per_text=tensor([[16.2034, 16.2034]], grad_fn=<MulBackward0>), text_embeds=tensor([[ 9.8798e-03, -1.8297e-03,  1.9789e-02, -2.5857e-02,  1.9348e-03,\n",
       "          3.9474e-03,  6.0765e-03, -1.4420e-02,  1.6274e-02, -1.9260e-02,\n",
       "         -1.6453e-03, -2.5102e-03, -2.3597e-02,  1.1575e-02, -1.0197e-02,\n",
       "          3.7195e-03,  1.4770e-02,  9.2950e-03, -7.1520e-03,  1.6400e-03,\n",
       "          1.1668e-02, -5.7529e-03, -3.5134e-03, -3.4461e-03,  9.8475e-03,\n",
       "         -2.4146e-02,  1.7663e-02,  3.7820e-03,  3.7147e-02,  1.0968e-02,\n",
       "         -1.3619e-02, -7.2178e-03, -1.9867e-02, -1.2346e-02, -1.6044e-02,\n",
       "          1.8504e-02,  4.6477e-03, -2.4104e-02, -8.4608e-03, -2.4040e-02,\n",
       "         -5.6259e-03, -5.6369e-03,  7.0979e-03,  4.5978e-03,  1.1762e-02,\n",
       "         -2.1662e-02,  4.2041e-03, -4.9361e-03, -1.3477e-02, -2.2331e-02,\n",
       "         -2.3357e-03, -7.8273e-03,  6.1767e-03, -4.4492e-03,  3.4784e-03,\n",
       "         -8.1112e-03, -1.4757e-03,  3.2482e-03,  1.1110e-02, -1.3281e-03,\n",
       "         -4.0961e-03,  1.0008e-02, -6.1375e-03,  1.0409e-02, -3.8014e-03,\n",
       "          1.1406e-02,  2.3413e-02, -3.4251e-03, -6.4141e-04, -2.2553e-02,\n",
       "         -5.8994e-03,  4.2785e-02, -1.4600e-03,  7.2344e-03, -7.4079e-03,\n",
       "          1.7202e-02, -3.2153e-03,  9.1997e-03, -1.1205e-04, -2.7817e-02,\n",
       "         -1.2810e-02,  7.8605e-04,  7.5547e-03, -6.6000e-03, -5.6104e-04,\n",
       "          1.7954e-02, -2.9842e-03,  8.0763e-03, -2.0338e-02,  4.0617e-02,\n",
       "         -3.7066e-03,  1.6975e-02, -1.5027e-02,  1.5696e-02, -1.5108e-02,\n",
       "          1.0369e-03,  1.3122e-02,  1.0259e-03,  2.4621e-02,  2.1057e-03,\n",
       "         -1.6282e-02, -1.1825e-02, -1.1166e-02, -1.3621e-03,  7.4719e-03,\n",
       "          6.0081e-03,  3.3997e-03, -1.7425e-02,  1.1540e-02, -1.4007e-02,\n",
       "         -5.9573e-03, -2.0930e-03, -1.0365e-02,  7.5891e-03, -4.3682e-03,\n",
       "          4.7598e-03, -3.3015e-02, -1.7998e-02, -2.0160e-03, -9.1675e-04,\n",
       "          3.9327e-03, -2.0321e-02, -3.2675e-04,  7.1115e-03, -2.4658e-03,\n",
       "         -3.9121e-03,  1.1613e-03,  9.3815e-03, -1.4740e-02, -1.8333e-02,\n",
       "          1.1892e-02, -3.7593e-02,  1.1503e-03, -2.0678e-02,  1.3434e-02,\n",
       "          2.3460e-02,  9.1994e-03,  2.7535e-02, -9.4500e-03,  1.2836e-02,\n",
       "          3.1505e-02,  1.9511e-03,  3.3910e-03, -1.6137e-02,  3.0095e-03,\n",
       "          5.3524e-03,  2.5298e-02, -2.1337e-02, -4.0743e-02,  1.5358e-03,\n",
       "          6.2105e-03, -1.3563e-02,  2.8975e-02, -6.0897e-03,  2.5324e-02,\n",
       "         -3.7293e-03,  1.5222e-02,  1.2280e-02,  1.8787e-03,  8.9237e-03,\n",
       "          1.2655e-02,  1.9565e-02,  8.8444e-04,  1.5811e-02,  1.0829e-03,\n",
       "         -8.1319e-03,  1.6852e-02, -9.3524e-03,  1.5482e-02, -2.7649e-02,\n",
       "          9.5718e-03, -2.5464e-02,  1.7650e-02, -3.9600e-03,  2.7311e-04,\n",
       "         -7.9631e-03,  6.5577e-03, -8.5353e-02,  1.4785e-02,  1.0002e-02,\n",
       "          5.1387e-02,  3.2027e-03, -2.8826e-02, -1.4640e-03, -8.0343e-03,\n",
       "         -4.3808e-03, -5.4689e-03,  5.9746e-03, -1.0015e-03, -1.7759e-02,\n",
       "         -1.7971e-02, -1.1426e-02,  1.1216e-02, -4.7796e-04,  6.5296e-03,\n",
       "         -1.3398e-01, -2.0630e-03,  2.4140e-02, -2.0120e-03,  4.3020e-03,\n",
       "          1.3173e-02, -8.2417e-04, -5.6228e-03,  5.0844e-03,  4.1724e-03,\n",
       "         -1.9605e-03, -9.9409e-03, -3.6112e-03,  3.0491e-02, -1.7362e-03,\n",
       "         -1.7154e-03, -2.1388e-03, -6.0047e-03,  1.5336e-02,  1.0271e-02,\n",
       "          1.1442e-02,  1.4368e-02,  1.4274e-02,  4.9571e-03,  2.7695e-02,\n",
       "          6.8591e-03, -1.8808e-02, -4.7082e-05, -3.9562e-03,  3.4815e-03,\n",
       "         -4.7610e-04, -6.8166e-03,  3.6389e-03,  2.4609e-02, -4.5117e-03,\n",
       "          8.8576e-03,  1.3487e-03, -9.2935e-03, -1.8958e-02,  7.8133e-03,\n",
       "         -1.4073e-02, -1.8255e-02,  9.5645e-03,  2.6784e-02, -8.0295e-03,\n",
       "          1.7072e-02, -2.6577e-03,  1.2546e-02,  7.5459e-03,  1.2086e-03,\n",
       "          3.9392e-02,  1.9113e-03,  1.6556e-02,  1.6261e-03,  2.9783e-02,\n",
       "          5.2669e-03,  2.4268e-04,  1.0421e-02, -1.3831e-02,  1.3198e-02,\n",
       "          1.3130e-02, -4.3147e-03,  2.4099e-02,  1.0723e-02,  4.8355e-02,\n",
       "         -1.2217e-02,  3.0306e-03, -2.9674e-04,  1.1674e-02,  1.0847e-02,\n",
       "          8.8581e-03,  5.9295e-04, -3.3174e-02,  3.4284e-03, -1.1863e-02,\n",
       "         -2.0654e-02,  1.7936e-03,  1.5532e-02, -1.5196e-02, -9.2520e-03,\n",
       "         -1.9998e-02, -9.3581e-04,  4.7779e-03,  1.1829e-02,  4.7618e-03,\n",
       "         -1.4307e-02, -4.5684e-02, -1.4181e-02,  4.5564e-03,  6.4766e-03,\n",
       "          6.6981e-03,  1.9037e-02,  6.7047e-03, -1.2968e-01, -3.6087e-03,\n",
       "         -9.4259e-03, -3.9015e-03, -4.3612e-02,  3.5164e-03,  6.5231e-04,\n",
       "         -4.0692e-03, -2.6663e-02,  1.3205e-02,  1.2427e-02, -1.0200e-02,\n",
       "         -1.1567e-02, -6.9009e-03, -1.7678e-02, -7.4939e-03,  6.4844e-03,\n",
       "         -1.2664e-03, -4.6637e-03, -4.9677e-03,  1.3414e-02, -7.8244e-03,\n",
       "         -3.1820e-02, -6.0936e-03, -3.4180e-03, -9.6437e-03,  2.0081e-02,\n",
       "         -8.3527e-03, -6.4482e-01,  6.6174e-03, -2.9589e-02,  5.7235e-03,\n",
       "         -3.6519e-03, -3.5795e-02,  1.2047e-02,  9.3907e-03, -1.4802e-02,\n",
       "          2.0919e-02, -4.6873e-02,  3.2716e-04,  2.7715e-03, -9.7512e-03,\n",
       "         -6.6361e-04,  1.0389e-02, -6.1242e-03, -1.0462e-02,  1.8214e-02,\n",
       "          5.3380e-03, -8.1676e-03,  1.7257e-03, -2.2342e-02, -2.8348e-02,\n",
       "         -4.9135e-03, -9.4503e-03, -3.2800e-03,  7.9804e-03, -2.7542e-04,\n",
       "         -4.8320e-03,  1.1132e-02,  3.6132e-03,  1.8040e-02,  1.3136e-02,\n",
       "         -5.7657e-04, -5.9422e-03, -1.8177e-03,  2.3604e-02,  1.9348e-02,\n",
       "         -8.7267e-03,  3.9693e-02, -5.6720e-03, -1.5509e-03, -1.4536e-02,\n",
       "          4.4614e-03,  8.8396e-03,  3.8345e-02,  2.0111e-02,  1.9247e-02,\n",
       "          1.8202e-02,  2.1617e-02,  1.2162e-02, -1.4823e-03,  1.5131e-02,\n",
       "          4.0117e-03,  1.3442e-02,  4.3021e-03, -2.4837e-03, -6.3821e-03,\n",
       "          4.5249e-03, -1.8336e-02, -1.1722e-03,  1.1558e-02, -9.6289e-03,\n",
       "          1.8689e-02, -1.9376e-02, -1.1460e-02,  3.6072e-03,  1.0989e-02,\n",
       "         -1.7918e-02,  1.8527e-02, -6.5723e-03,  1.7115e-03,  7.5095e-03,\n",
       "          1.4778e-02, -5.7017e-03, -1.1774e-02,  6.0340e-04, -2.1736e-02,\n",
       "         -2.6536e-02, -4.6666e-03,  5.3046e-03, -1.1058e-03,  1.8783e-02,\n",
       "          2.8736e-02,  1.1957e-02,  4.3963e-03, -6.6892e-03,  6.6450e-02,\n",
       "          1.0522e-02,  8.9411e-03, -1.3207e-03,  2.2468e-03,  1.8251e-02,\n",
       "          4.8210e-03, -2.5708e-02,  5.3515e-03, -6.9132e-02, -1.2633e-03,\n",
       "          8.8554e-03, -1.4762e-02, -9.2790e-03, -1.9434e-02, -5.9938e-03,\n",
       "         -2.0876e-02,  1.9970e-03,  5.4620e-03, -1.0932e-02, -8.0111e-03,\n",
       "          7.0610e-03, -3.3346e-03, -4.7385e-04,  1.4198e-02,  1.1050e-02,\n",
       "         -1.0664e-02,  9.5158e-03,  1.3794e-02, -4.2957e-03,  1.7466e-02,\n",
       "          4.3661e-02, -9.0103e-03, -5.5561e-03, -8.5804e-03,  1.1712e-02,\n",
       "          5.8837e-01, -8.1015e-04,  5.9944e-03,  1.8521e-02, -1.2710e-02,\n",
       "         -2.6700e-03,  2.6129e-02,  1.5086e-02,  1.2767e-03, -1.6981e-02,\n",
       "         -6.5802e-02, -1.6052e-02,  3.5126e-02,  5.7038e-03, -9.9973e-03,\n",
       "          3.5355e-02,  2.0658e-02,  1.0669e-03, -1.5170e-02,  1.1988e-02,\n",
       "         -1.5481e-02,  9.1591e-03,  5.7426e-03,  2.4671e-02,  1.2664e-03,\n",
       "         -8.1328e-03,  1.1847e-02,  2.6328e-02,  1.3775e-02,  8.5692e-03,\n",
       "          8.9580e-03, -5.7568e-03,  1.1979e-02,  2.2255e-04,  1.3422e-03,\n",
       "         -1.5249e-02,  1.7210e-02,  3.5334e-03, -2.1586e-02, -7.2111e-03,\n",
       "         -7.8791e-03, -1.7540e-02, -1.9974e-02, -2.3083e-02, -1.8284e-02,\n",
       "          9.8674e-03,  1.6422e-02, -2.7679e-02,  6.5134e-03,  2.5301e-02,\n",
       "          2.1267e-04,  1.1625e-02, -3.4312e-02, -9.0471e-03, -4.9173e-04,\n",
       "          3.4944e-03,  1.3229e-03, -2.4370e-02,  3.8717e-03,  5.3565e-03,\n",
       "          1.1118e-02, -2.1291e-02, -1.5364e-03,  1.1633e-02, -1.6890e-02,\n",
       "         -6.4522e-03, -7.9641e-03, -1.4873e-02, -4.3850e-02, -3.0228e-04,\n",
       "          1.0060e-02, -1.9543e-02, -1.9058e-03,  1.7158e-03, -3.9675e-04,\n",
       "          2.1870e-03, -1.0395e-03, -1.8076e-02, -8.8772e-03, -1.9720e-02,\n",
       "          9.9914e-03, -2.2450e-02, -1.1786e-02, -2.3277e-04,  3.5269e-03,\n",
       "          2.5542e-02,  9.2327e-03,  1.2345e-02, -8.8518e-02, -1.7297e-02,\n",
       "         -2.5088e-02, -2.2863e-02,  2.3748e-03, -3.2693e-03,  1.9126e-02,\n",
       "          9.2478e-04, -1.1429e-02,  9.9115e-03, -4.1112e-02,  5.9850e-05,\n",
       "         -1.8995e-03,  8.9801e-03,  5.1281e-04,  6.8555e-04, -1.2573e-02,\n",
       "         -2.9827e-03,  9.4253e-03, -4.6507e-03,  6.5241e-03,  5.4864e-03,\n",
       "          1.9469e-02, -1.2595e-02,  2.5399e-03, -6.9855e-04,  3.0314e-03,\n",
       "          1.7982e-02,  8.8280e-04,  1.7813e-02,  2.5264e-03, -4.4103e-03,\n",
       "          2.5338e-02,  2.5239e-02, -1.2381e-02,  6.1575e-03,  3.9858e-02,\n",
       "          1.6285e-02,  8.0113e-03,  2.4588e-03, -1.7391e-03,  1.5989e-02,\n",
       "          1.8850e-02, -2.6047e-02, -1.2802e-02, -1.0810e-02,  1.2935e-02,\n",
       "         -2.2781e-02,  1.3537e-02,  5.2357e-03, -6.4822e-04, -1.3481e-02,\n",
       "          1.3082e-02, -3.3418e-04, -1.0255e-02,  1.2431e-02, -2.2325e-02,\n",
       "         -3.1375e-02,  1.1805e-02, -8.8582e-03, -4.8078e-03, -1.1455e-02,\n",
       "          4.5340e-03,  6.2078e-03, -1.1838e-02, -5.5912e-03,  2.1883e-02,\n",
       "          1.0779e-02,  8.8339e-03, -1.4227e-02,  3.5858e-03,  1.2830e-02,\n",
       "         -1.2853e-02,  1.9991e-02,  2.8457e-03,  1.2259e-02,  9.2305e-04,\n",
       "          2.4039e-02,  7.1313e-03,  8.0864e-03, -2.7634e-04, -2.6681e-04,\n",
       "          3.2607e-03,  2.0429e-04, -1.2793e-02, -9.7656e-04, -8.6901e-03,\n",
       "         -5.3069e-03,  8.8346e-03, -4.6210e-02, -2.2187e-03,  2.8356e-03,\n",
       "          9.8962e-03,  1.7286e-03, -6.7818e-03,  1.4410e-02, -2.9645e-02,\n",
       "          2.6093e-02,  1.3878e-02, -9.1486e-03,  1.3590e-02, -5.4703e-03,\n",
       "         -6.1807e-03,  2.8431e-02, -1.7649e-03, -4.7907e-03,  5.8908e-03,\n",
       "          7.7234e-03,  1.2704e-02, -3.0350e-02, -3.5381e-03, -6.5263e-03,\n",
       "         -3.3538e-03,  1.2100e-02, -1.1899e-03, -1.2917e-02,  6.9401e-02,\n",
       "          3.8237e-03,  7.2815e-03, -9.1608e-03,  3.0845e-02, -3.9083e-03,\n",
       "          1.5064e-02, -1.7849e-02, -1.7256e-02,  4.0138e-03,  2.2937e-02,\n",
       "          7.2514e-03,  8.0128e-03, -9.7483e-03, -2.4028e-03, -3.6849e-02,\n",
       "         -2.4993e-02, -1.2266e-02, -1.0514e-02,  1.3630e-02, -2.3665e-03,\n",
       "          1.2496e-03,  1.0954e-02, -7.5802e-03, -7.8004e-03,  9.5023e-03,\n",
       "         -1.2990e-02,  1.5194e-02,  8.2273e-03,  7.9458e-03, -9.1232e-03,\n",
       "         -1.3658e-02,  1.3846e-02, -1.0010e-02, -6.3757e-03, -1.3406e-02,\n",
       "         -1.1182e-02,  7.3570e-04, -1.8146e-02, -1.7829e-02,  2.1988e-02,\n",
       "          2.3283e-02, -1.5694e-02,  8.4832e-03,  8.0457e-03, -1.2514e-03,\n",
       "          1.8278e-02,  6.5929e-03, -1.2087e-02, -4.4946e-03,  1.4454e-02,\n",
       "          2.7261e-03, -3.4871e-03,  1.3615e-02, -1.3606e-03, -1.3758e-02,\n",
       "          4.4285e-03,  4.1773e-03, -1.2458e-03, -4.8999e-02,  1.6052e-02,\n",
       "          2.1316e-02, -5.4366e-03, -3.9881e-03,  3.0762e-04, -1.2355e-02,\n",
       "         -1.7314e-02,  2.5888e-02, -4.8754e-03,  1.8090e-02,  2.0657e-02,\n",
       "         -1.2072e-02, -1.8156e-03, -7.3599e-03,  3.6642e-03,  7.4796e-03,\n",
       "         -2.2067e-03,  9.8127e-04,  1.4105e-02, -3.0854e-02,  4.2074e-02,\n",
       "          2.9146e-02,  7.0942e-03,  3.1866e-03, -2.6195e-02,  9.7905e-03,\n",
       "         -1.7907e-03,  9.9851e-03,  9.8079e-03, -8.6305e-03,  2.9619e-02,\n",
       "          7.5290e-03,  2.0086e-02,  9.1043e-03,  1.4751e-02,  2.3548e-02,\n",
       "          1.3017e-02,  3.0045e-02,  2.9079e-04,  2.5286e-02,  3.7252e-03,\n",
       "         -5.9291e-03,  9.9374e-04, -2.1567e-03, -2.8258e-05, -2.2485e-02,\n",
       "         -1.1179e-02, -1.0363e-02,  1.2755e-02,  3.9942e-03, -1.6063e-02,\n",
       "         -1.9792e-02,  2.3604e-02,  1.4668e-02, -1.1896e-02, -1.8221e-02,\n",
       "         -6.7480e-03, -3.1630e-02,  3.2448e-02,  1.4325e-02,  3.5737e-02,\n",
       "         -1.1809e-02, -2.3379e-02,  5.2581e-03]], grad_fn=<DivBackward0>), image_embeds=tensor([[-0.0316,  0.0731, -0.0006,  ..., -0.0510,  0.0005, -0.0026],\n",
       "        [-0.0316,  0.0731, -0.0006,  ..., -0.0510,  0.0005, -0.0026]],\n",
       "       grad_fn=<DivBackward0>), text_model_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],\n",
       "         [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-3.7112e-01, -1.4497e+00, -3.4011e-01, -1.0820e-01, -1.4188e+00,\n",
       "          3.1752e-01, -1.8571e-01, -2.3674e-01, -1.1044e+00,  9.0634e-01,\n",
       "         -6.7430e-01,  8.8501e-01,  2.3569e+00, -5.3967e-01,  4.1692e-01,\n",
       "          8.4393e-02, -1.5438e+00,  1.8802e+00, -3.1700e-01, -2.3928e-01,\n",
       "         -1.1967e+00,  1.6942e+00, -1.4265e+00, -6.4020e-01, -5.6384e-01,\n",
       "          9.8448e-01,  7.3632e-01, -1.4914e+00, -5.0299e-01, -2.0890e-01,\n",
       "         -1.8133e+00,  7.1496e-01, -1.0035e+00, -1.6736e-01,  3.1006e-02,\n",
       "          4.5237e-02, -6.5507e-01, -2.2653e+00, -1.2030e+00,  1.5792e+00,\n",
       "          8.3512e-01, -9.9550e-01, -2.0398e-01, -8.4623e-01,  2.3312e-01,\n",
       "         -4.8495e-01, -5.8106e-02, -7.1539e-01, -1.8860e-01, -1.0971e-01,\n",
       "          1.2541e+00, -2.7065e-01,  4.3963e-01,  1.4382e+00,  6.8527e-01,\n",
       "         -8.3698e-01,  1.3836e-01, -1.9559e-01, -9.1402e-01, -7.9256e-01,\n",
       "          4.3814e-01,  5.1845e-01, -6.5202e-01, -5.1703e-01, -1.4772e+00,\n",
       "          8.4105e-02, -5.5211e-01,  6.4823e-01, -1.2988e+00,  7.3880e+00,\n",
       "         -5.1862e-01, -9.3581e-01, -6.4044e-01,  1.3738e+00,  6.0500e-01,\n",
       "          1.8548e+00, -2.3708e+00,  6.3858e-01,  8.9227e-01, -1.1174e+00,\n",
       "         -8.0923e-01,  1.6169e+00, -1.0027e+00,  4.1526e-01, -1.1909e+00,\n",
       "         -1.1579e+00,  3.9778e-01, -1.5538e-01, -5.5012e-01, -1.2486e+00,\n",
       "          4.8696e-01, -6.3175e-01,  9.1147e-01,  8.9408e-01, -1.3620e-01,\n",
       "          4.0682e-01, -7.2419e-01,  2.9531e-01,  2.8647e-01, -5.1563e-01,\n",
       "         -2.0785e+00, -1.0487e+00,  4.6351e-01, -2.5448e-01, -2.5407e+00,\n",
       "         -5.6764e-01, -8.6118e-01, -4.8524e-01, -8.0686e-01, -1.7200e+00,\n",
       "          9.3651e-01, -6.3111e-01, -4.8518e-01, -5.2051e-01, -8.4019e-01,\n",
       "          6.0743e-01,  9.1998e-01,  1.0730e+00,  5.7042e-01, -1.2349e+00,\n",
       "          1.9272e+00,  4.0864e-01,  7.7900e-01, -2.8444e-01, -1.0568e+00,\n",
       "          1.0622e+00, -5.1189e-01, -2.7323e-02, -8.6234e-01, -3.2197e-01,\n",
       "         -5.6644e-01,  9.6968e-01, -1.3383e+00, -5.2525e-01,  8.7814e-01,\n",
       "         -1.4469e+00, -1.3219e+00,  7.9769e-01,  3.7216e-01,  6.5912e-01,\n",
       "          3.4531e-01,  3.3187e-01, -5.5802e-01, -2.7438e-01, -8.1362e-01,\n",
       "          6.9161e-01, -2.8392e-02, -7.5141e-01,  3.3372e-02, -9.1191e-01,\n",
       "         -1.5864e+00, -4.3935e-01,  9.1609e-01,  5.7234e-01, -9.7326e-01,\n",
       "          5.4235e+00, -1.3650e+00,  2.2547e-01, -1.0170e+00, -1.7866e+00,\n",
       "         -1.4861e+00, -1.3542e-01,  4.1692e-02, -7.0478e-01,  1.3269e-01,\n",
       "         -3.6137e-01, -4.3324e-01,  1.0283e+00,  1.5349e-01, -1.2130e+00,\n",
       "         -6.7729e-01, -9.7532e-01,  7.7440e-02,  5.0958e-01, -1.2313e+00,\n",
       "         -1.1535e-01, -4.2322e-01,  3.3633e-01, -2.6125e-01, -6.6597e-01,\n",
       "          1.4794e+00,  3.3180e-02, -1.9320e-01,  7.7480e-02, -7.1795e-01,\n",
       "         -1.4076e-01,  8.7989e-02, -4.1620e+00,  1.4027e+00,  1.6402e+00,\n",
       "          1.3398e+00, -4.3000e-02, -4.4773e-01, -2.4928e-02, -2.2124e-01,\n",
       "         -1.0607e+00,  6.4581e-01, -9.0637e-01, -4.2549e+00, -1.0237e+00,\n",
       "         -1.1900e+00, -2.0298e+00,  7.5810e-01,  3.8681e-01,  8.6754e-01,\n",
       "          3.3704e-01, -1.7184e+00, -1.3296e-01, -7.7598e-02, -6.0446e-01,\n",
       "          8.1607e-01, -8.2864e-01,  5.3559e-01, -3.2391e+00, -1.2297e-01,\n",
       "          9.1543e-03, -1.1811e-01, -5.6977e-01, -5.3702e-01, -3.6197e-01,\n",
       "          7.5798e-01,  9.6490e-01,  1.7074e+00, -1.0046e+00,  2.2507e+00,\n",
       "         -1.1135e+00,  1.6174e-01,  1.0401e+00,  1.9638e-01,  1.9085e-01,\n",
       "         -9.1754e-01, -9.0103e-01,  4.0119e-02,  6.4968e-01,  8.5728e-01,\n",
       "         -5.4792e-01,  4.1361e-01, -1.1984e+00, -3.5715e-01,  4.0976e-01,\n",
       "          9.7627e-01, -1.1835e-01, -1.9120e+00, -5.9777e-01, -8.8600e-01,\n",
       "          5.8889e-01, -1.1679e-01, -1.2045e+00, -4.3177e-02,  2.8389e-01,\n",
       "          6.8444e-01, -1.2246e-01, -7.8465e-03,  2.7455e-01, -1.0849e+00,\n",
       "          2.8888e-01, -8.6683e-01,  6.4567e-01,  1.8287e-01, -1.0007e-01,\n",
       "          1.5702e+00, -7.9579e-01,  2.0610e+00,  7.6541e-01, -1.6238e+00,\n",
       "          2.7111e-01,  1.2367e+00,  9.9030e-02, -3.2308e-01, -1.5876e-01,\n",
       "         -9.0263e-01, -5.2693e-01, -6.8416e-01, -4.3216e-01,  1.4913e+00,\n",
       "          7.7320e-01,  2.6500e-01, -4.8384e-01, -1.9734e-01,  6.3658e-01,\n",
       "          7.4178e-01,  1.2183e+00, -1.3235e+00, -4.0731e-01,  3.4305e-01,\n",
       "         -3.2135e-01,  7.8162e-01, -3.7663e-01, -1.3753e+00,  3.3862e-01,\n",
       "          9.7130e-01, -1.8542e-01, -1.9838e-01, -4.1059e-01, -1.2388e+00,\n",
       "          3.3436e-01, -1.6832e-01, -3.0461e-01, -3.3070e-01,  2.7752e-01,\n",
       "         -5.4744e-01, -9.3147e-01, -6.1478e-01,  7.8563e-01,  1.7554e-01,\n",
       "          1.2206e+00, -7.5458e-01, -5.5548e-01,  6.5505e-01, -1.1946e+00,\n",
       "         -7.6284e-01, -1.0911e+00, -6.8922e-01, -4.4108e-01,  1.1093e-01,\n",
       "         -9.7653e-01, -8.9308e-01,  1.4573e+00,  7.8468e-01, -1.7929e-01,\n",
       "          1.1538e+00, -4.8467e-01,  4.7752e-02,  6.3443e-01,  4.6619e+00,\n",
       "          6.5909e-01, -3.1264e-01, -1.1502e+00,  1.4170e-01,  1.0916e+00,\n",
       "          7.3593e-01, -9.0840e-01,  1.3939e-01, -5.8889e-01, -1.5396e+00,\n",
       "         -6.0269e-01,  1.6211e+00,  2.3909e-01,  4.8027e-01,  3.5771e-01,\n",
       "         -2.7887e-02,  1.3747e+00, -7.4743e-02,  7.5502e-01,  7.9013e-01,\n",
       "          1.3357e-01, -7.0349e-01,  2.4855e-01,  1.5213e+00,  1.0782e+00,\n",
       "          4.2189e-01,  3.8318e-01,  7.5882e-02, -1.7434e-02, -1.4251e+00,\n",
       "          4.5930e-01, -4.0498e-01,  9.5963e-02, -4.7697e-03,  1.5033e+00,\n",
       "         -1.4684e-01,  1.8644e+00, -9.1806e-01,  1.9701e-01,  1.5923e-01,\n",
       "          1.7165e-02, -2.5961e+00, -1.0389e+00, -1.2044e+00, -1.2755e+00,\n",
       "          1.3904e+00,  5.0930e-01, -7.9214e-01,  9.6552e-01, -7.4194e-01,\n",
       "         -1.0988e+00,  2.6666e-02, -6.9486e-01,  3.4397e-01,  6.7477e-01,\n",
       "          4.7854e-01,  1.7059e-01,  2.1595e-02, -5.4682e-01, -5.8375e-01,\n",
       "         -1.5834e+00, -1.7231e+00, -8.1381e-01, -3.9344e-02, -4.9473e-01,\n",
       "          3.1052e-01,  2.9281e-01,  2.1900e-02,  2.8096e-01, -1.1691e-01,\n",
       "         -2.1137e-01,  1.3103e+00, -1.6930e+00,  2.8203e-02, -1.7801e-01,\n",
       "         -8.4773e-01, -1.4237e+00, -7.3908e-01, -3.6995e-01, -1.6849e+00,\n",
       "         -6.5966e-02,  4.0321e-01, -3.9272e-01, -2.9601e-01, -9.9514e-01,\n",
       "          1.0766e-01, -7.4013e-02, -1.1545e+00, -1.6334e-01, -5.3320e+00,\n",
       "         -1.6605e+00,  1.1293e+00, -1.1091e+00,  7.3860e-01, -1.5425e+00,\n",
       "          7.2102e-02, -1.0022e+00, -1.2515e+00, -4.7224e-01,  2.5014e-02,\n",
       "         -1.9052e-02,  2.4082e+00, -3.2946e-01, -1.0454e+00,  2.5137e-01,\n",
       "         -9.4645e-02, -1.1743e+00, -3.9441e-01, -1.8221e+00, -3.3539e-01,\n",
       "          6.1425e-01,  6.1081e-01,  5.3205e-01, -6.3185e-02,  9.3770e-01,\n",
       "          1.0437e+00, -3.7076e-01, -9.1581e-01, -7.8952e-02,  1.1170e+00,\n",
       "          2.5710e-01, -1.3500e+00, -2.5660e-01,  7.1048e-01, -1.0499e+00,\n",
       "         -1.0896e-01, -2.7698e-01, -7.0273e-01, -1.2543e+00, -1.0615e+00,\n",
       "         -5.4820e-01, -6.8649e-01, -2.5649e-01,  6.9613e-01,  7.1212e-02,\n",
       "          1.9925e-01, -3.8777e-02,  5.0940e-01, -1.6542e-01, -6.6927e-01,\n",
       "          6.4505e-01,  2.8723e-01,  1.5255e+00, -2.2251e+00, -1.5272e+00,\n",
       "         -1.2150e+00,  7.3220e-01, -1.7735e-01, -1.1906e+00, -2.1654e-01,\n",
       "          1.3508e-01,  8.0314e-01,  4.2579e-01,  5.5450e-02,  1.0356e+00,\n",
       "          1.9023e-01,  1.3126e-01, -7.5420e-01, -2.9749e+00,  2.6431e-01,\n",
       "         -3.6189e-01,  4.6047e-01, -2.7276e-01, -4.2816e-02, -7.2264e-01,\n",
       "         -1.8817e+00, -9.3332e-01, -9.7756e-02, -2.1129e+00,  1.7822e+00,\n",
       "          8.7230e-01,  1.2389e+00, -8.1149e-01, -7.1396e-01, -1.3839e+00,\n",
       "         -2.8486e-02,  2.1238e+00,  9.3251e-02, -1.1364e+00, -4.5192e-02,\n",
       "          3.3906e-01, -3.7641e-01,  9.8172e-01,  5.7453e-01, -1.6239e+00,\n",
       "         -1.2108e+00,  4.0311e-02, -6.7619e-01,  2.8343e-01,  1.5027e+00,\n",
       "         -1.0208e-01, -3.4048e-01, -2.1211e+00, -1.9659e+00,  7.4094e-01,\n",
       "          6.2816e-01, -3.4593e-01,  1.2012e+00,  1.6112e+00,  2.7186e-01,\n",
       "         -1.2974e+00, -7.6110e-01, -8.3108e-01,  8.9582e-01,  2.1261e-01,\n",
       "         -1.5331e+00, -2.7819e-01,  3.2085e-01,  3.9809e-02, -5.0520e-02,\n",
       "         -4.4779e-01,  8.1795e-01, -1.5691e+00, -2.2781e-01, -8.5281e-02,\n",
       "          1.4615e+00,  1.1286e-01, -4.6600e-01, -9.6870e-01,  6.5896e-01,\n",
       "          2.6815e-01, -2.5291e-01, -3.7408e-01, -2.4571e-02, -9.6872e-01,\n",
       "          1.0558e+00, -9.1711e-01, -9.1805e-01, -4.2324e-02, -2.3725e-01,\n",
       "          5.4901e-01,  1.0221e+00,  5.5117e-01,  6.0127e-01, -7.5004e-01,\n",
       "          4.5301e-01, -3.1830e+00, -1.2620e+00, -1.3791e+00, -1.5047e+00,\n",
       "          1.3240e-01,  6.2684e-01,  3.3677e-02, -1.5294e-01, -8.3137e-01,\n",
       "          4.5382e-01,  1.1788e+00,  1.0796e+00,  1.7587e+00, -1.9519e-01,\n",
       "         -6.2449e-01, -4.9073e-01, -3.2753e-01, -6.2223e-01,  1.4717e+00,\n",
       "          2.6265e-01, -1.9571e-01, -1.1327e+00, -2.5129e+00, -1.9495e-01,\n",
       "          5.0289e-01, -4.4181e-01, -1.7857e+00, -1.5202e+00, -5.4480e-01,\n",
       "          2.7027e-02, -7.8048e-01, -8.5068e-01,  1.2858e+00,  4.7036e-01,\n",
       "          1.2669e+00,  9.8509e-01,  3.0838e-01,  2.0264e-01,  1.9358e+00,\n",
       "         -2.3204e-01, -3.2931e-01, -6.0274e-01, -4.6784e-01, -4.8345e-01,\n",
       "          2.5174e-01, -1.7563e+00, -2.0197e-01,  1.6018e-01, -3.6700e-01,\n",
       "          8.2138e-01,  6.1275e-01,  3.8096e-02,  3.2834e-01, -1.2864e-01,\n",
       "         -6.0197e-01,  7.2400e-01, -5.9407e-01,  3.0047e-01, -9.1713e-01,\n",
       "          1.1395e+00, -5.3715e-02, -1.7944e-01,  2.2797e-01,  6.9970e-01,\n",
       "         -7.7448e-01,  9.0398e-01, -3.7739e-01, -1.1534e+00,  2.5838e-01,\n",
       "         -3.4512e-01, -3.4068e-01, -7.7642e-01, -3.4842e-01, -2.0520e+00,\n",
       "          9.9390e-01, -5.2207e-02,  1.3416e+00, -9.4127e-02,  4.2430e-01,\n",
       "         -6.9319e-01,  1.0760e-01, -7.5915e-01,  5.5050e-03,  2.2011e+00,\n",
       "         -1.3537e-01,  5.9392e-02, -1.2886e+00, -3.0862e-01,  6.6462e-01,\n",
       "         -5.6734e-01, -1.9318e-01,  3.3483e-02, -1.1153e+00,  7.6895e-01,\n",
       "         -1.0672e+00,  4.6706e-01, -2.8829e-01, -1.6800e-01, -2.0433e+00,\n",
       "          7.7606e-01, -1.1750e+00, -5.5939e-01,  1.4340e-01,  8.4400e-01,\n",
       "         -5.3318e-01,  1.1828e+00, -6.9000e-01,  4.3603e-01, -9.8369e-01,\n",
       "          3.6954e-01,  5.6255e-01, -2.4857e-01, -1.7171e-01, -7.4361e-01,\n",
       "          8.7289e-01, -1.3080e-01, -2.4431e-01, -4.8296e-01, -1.7440e+00,\n",
       "         -9.1951e-02,  6.2407e+00,  1.8583e-01,  3.4195e-01, -1.1306e-01,\n",
       "         -6.5853e-01, -1.0531e+00,  6.3263e-01,  1.0782e+00, -1.8809e+00,\n",
       "          8.0443e-01,  1.7498e-01, -2.8775e-01,  2.9101e-01, -8.8678e-01,\n",
       "         -3.6430e-01,  2.6685e+00, -3.0254e-01,  1.5653e-01, -1.0594e+00,\n",
       "         -3.3848e-01, -2.6366e-01, -1.1534e+00,  3.9449e-01, -2.2909e-01,\n",
       "          1.1056e+00,  3.2123e-01, -4.6335e-02, -7.0757e-01, -1.4902e-01,\n",
       "         -3.7501e-01,  2.4334e-02, -1.1329e+00, -8.1806e-01,  1.0159e+00,\n",
       "         -1.2488e+00,  2.6302e-01,  6.4476e-01, -4.5710e-01,  1.7556e+00,\n",
       "          5.0647e-01,  1.5800e-01,  8.8056e-01,  1.9683e+00, -3.1136e-02,\n",
       "          3.6356e-01,  5.2655e+00, -6.9016e-01, -8.2797e-02, -6.5190e-01,\n",
       "         -1.9570e-01,  2.5790e-01,  5.5311e-01, -1.0539e+00, -1.1221e+00,\n",
       "         -5.7618e-01, -1.9795e+00, -1.1418e+00,  5.9617e-01,  1.1314e+00,\n",
       "          8.3411e-01,  6.8664e-01, -1.0640e+00, -6.9835e-01,  1.9779e-01,\n",
       "          8.0523e-01,  5.5751e-01, -8.2204e-01, -9.6867e-01,  5.7481e-01,\n",
       "          3.5579e-01,  1.2703e+00, -4.2901e-01,  2.9364e-01, -1.1363e+00,\n",
       "         -9.1832e-01, -8.5334e-01, -4.8374e-01,  6.7298e-01,  5.7216e-01,\n",
       "          5.6353e-02,  1.0211e+00, -8.1743e-01,  5.0487e-01,  1.8479e+00,\n",
       "          9.4886e-01,  1.8672e-01, -1.1034e+00]], grad_fn=<IndexBackward0>), hidden_states=None, attentions=None), vision_model_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.5297, -0.7713,  0.4655,  ..., -0.3993, -0.0721, -0.3703],\n",
       "         [ 0.8688,  0.1690,  0.6678,  ...,  0.5126, -1.1465, -0.1258],\n",
       "         [ 1.1742, -0.7551,  0.0396,  ...,  0.7166, -0.5458,  0.0031],\n",
       "         ...,\n",
       "         [ 0.8636,  0.2223,  0.6411,  ...,  0.5242, -0.8104,  0.0170],\n",
       "         [ 0.6842, -1.1056, -0.2486,  ...,  0.7901,  0.4862, -0.0949],\n",
       "         [ 0.8934,  0.0066,  0.9236,  ...,  0.5707, -0.8436, -0.2182]],\n",
       "\n",
       "        [[-0.5297, -0.7713,  0.4655,  ..., -0.3993, -0.0721, -0.3703],\n",
       "         [ 0.8688,  0.1690,  0.6678,  ...,  0.5126, -1.1465, -0.1258],\n",
       "         [ 1.1742, -0.7551,  0.0396,  ...,  0.7166, -0.5458,  0.0031],\n",
       "         ...,\n",
       "         [ 0.8636,  0.2223,  0.6411,  ...,  0.5242, -0.8104,  0.0170],\n",
       "         [ 0.6842, -1.1056, -0.2486,  ...,  0.7901,  0.4862, -0.0949],\n",
       "         [ 0.8934,  0.0066,  0.9236,  ...,  0.5707, -0.8436, -0.2182]]],\n",
       "       grad_fn=<AddBackward0>), pooler_output=tensor([[-0.9326, -1.3289,  0.7919,  ..., -0.3337, -0.0479, -0.7106],\n",
       "        [-0.9326, -1.3289,  0.7919,  ..., -0.3337, -0.0479, -0.7106]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(text=[\"\"], images=[image, image], return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'miner' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['miner'])`.\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lib.utils import load_config\n",
    "from lib.models.siamese import Siamese\n",
    "from lightning import Trainer\n",
    "from lib.eval.tester import SiameseTester\n",
    "from pathlib import Path\n",
    "from lib.data.siamese_datamodule import SiameseDataModule\n",
    "import hydra\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "cfg = load_config(\"eval_siamese\", overrides=[\"+experiment=eval\"])\n",
    "cfg.ckpt_path = \"/home/borth/sketch2shape/logs/train/runs/2023-12-10_20-29-37/checkpoints/last.ckpt\"\n",
    "model = Siamese.load_from_checkpoint(cfg.ckpt_path)\n",
    "tester = SiameseTester(model=model.decoder)\n",
    "datamodule = hydra.utils.instantiate(cfg.data, train=False)\n",
    "datamodule.setup(\"all\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: /home/borth/sketch2shape/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaed0d7beb1475ca7f2e33d0625ef92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "class EvalCLIP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_size = 768\n",
    "        self.model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "        self.processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        inputs = processor(text=[\"\"], images=batch, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        return outputs.image_embeds\n",
    "\n",
    "model = EvalCLIP()\n",
    "tester = SiameseTester(model=model)\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=1,\n",
    "    enable_checkpointing=False,\n",
    ")\n",
    "trainer.validate(\n",
    "    tester,\n",
    "    dataloaders=[\n",
    "        datamodule.test_dataloader(),\n",
    "        datamodule.val_dataloader(),\n",
    "    ],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
