{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.visualize.open3d import visualize_object, visualize_pointcloud\n",
    "\n",
    "obj_id = 3\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "surface_samples = metainfo.load_surface_samples(metainfo.obj_ids[obj_id])\n",
    "mesh = metainfo.load_normalized_mesh(metainfo.obj_ids[obj_id])\n",
    "visualize_object(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = mesh.sample_points_uniformly(number_of_points=500)\n",
    "visualize_pointcloud(samples.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pointcloud(surface_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earth Movers Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "s = time.time()\n",
    "num_samples = 5000\n",
    "emd = []\n",
    "for i in range(1):\n",
    "    np.random.seed(1)\n",
    "    idx = np.random.choice(range(len(surface_samples)), num_samples, replace=False)\n",
    "    gt_samples = surface_samples[idx]\n",
    "    samples = np.asarray(mesh.sample_points_uniformly(number_of_points=num_samples).points)\n",
    "    d = cdist(gt_samples, samples)\n",
    "    assignment = linear_sum_assignment(d)\n",
    "    _emd = d[assignment].sum() / min(len(gt_samples), len(samples))\n",
    "    emd.append(_emd)\n",
    "np.mean(emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pointcloud(gt_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.visualize.open3d import visualize_object, visualize_pointcloud\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import numpy as np\n",
    "from lib.data.metainfo import MetaInfo\n",
    "from lib.data.transforms import BaseTransform\n",
    "import hydra\n",
    "from lib.utils.config import load_config\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from lib.visualize.image import image_grid\n",
    "\n",
    "\n",
    "def siamese_loss(emb_1, emb_2):\n",
    "    return 1 - cosine_similarity(emb_1, emb_2)\n",
    "\n",
    "\n",
    "def transform(normal):\n",
    "    _transform = BaseTransform()\n",
    "    return _transform(normal).to(\"cuda\")\n",
    "\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image)\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "obj_id = 0\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "cfg = load_config(\"optimize_sketch\", [\"+dataset=shapenet_chair_4096\"])\n",
    "metainfo = MetaInfo(cfg.data.data_dir)\n",
    "\n",
    "cfg.loss_ckpt_path = \"/home/borth/sketch2shape/checkpoints/latent_encoder.ckpt\"\n",
    "cfg.model.shape_k = 16\n",
    "cfg.model.shape_view_id = 11\n",
    "cfg.model.shape_init = False\n",
    "cfg.model.shape_prior = False\n",
    "cfg.model.obj_id = metainfo.obj_ids[0]\n",
    "model = hydra.utils.instantiate(cfg.model).to(\"cuda\")\n",
    "\n",
    "surface_samples = metainfo.load_surface_samples(metainfo.obj_ids[obj_id])\n",
    "mesh = metainfo.load_normalized_mesh(metainfo.obj_ids[obj_id])\n",
    "visualize_object(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch = np.asarray(metainfo.load_image(4030, 11, 0))\n",
    "model.latent = model.loss(transform(sketch)[None, ...])[0]\n",
    "rendered_normal = model.capture_camera_frame().detach().cpu().numpy()\n",
    "plot_images([sketch,rendered_normal], size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "_ = torch.manual_seed(123)\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "fid = FrechetInceptionDistance(feature=2048)\n",
    "# generate two slightly overlapping image intensity distributions\n",
    "\n",
    "imgs_dist1 = torch.randint(0, 200, (100, 3, 256, 256), dtype=torch.uint8)\n",
    "imgs_dist2 = torch.randint(100, 255, (100, 3, 256, 256), dtype=torch.uint8)\n",
    "fid.update(imgs_dist1, real=True)\n",
    "fid.update(imgs_dist2, real=False)\n",
    "fid.compute()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
