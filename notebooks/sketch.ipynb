{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.data.metainfo import MetaInfo\n",
    "\n",
    "def plot_images(images, size: int = 4):\n",
    "    if isinstance(images, list):\n",
    "        _, axes = plt.subplots(1, len(images), figsize=(size, size))\n",
    "        for ax, image in zip(axes, images):\n",
    "            ax.imshow(image.permute(1, 2, 0).detach().cpu().numpy())\n",
    "            ax.axis(\"off\")  # Turn off axis\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(size, size))\n",
    "        plt.imshow(images.permute(1, 2, 0).detach().cpu().numpy())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Sketch Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = 90\n",
    "metainfo = MetaInfo(data_dir=\"/home/borth/sketch2shape/data/shapenet_chair_4096\")\n",
    "trans = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "sketch = metainfo.load_sketch(metainfo.obj_ids[obj_id], \"00011\")\n",
    "sketch = 1 - trans(sketch)\n",
    "\n",
    "images = []\n",
    "for kernel_size in range(1,10):\n",
    "    conv = torch.nn.Conv2d(3, 3, kernel_size=kernel_size, padding=\"same\", stride=(1,), bias=False)\n",
    "    conv.weight = torch.nn.Parameter(torch.ones_like(conv.weight))\n",
    "    _sketch = sketch\n",
    "    _sketch = v2.functional.pad(sketch, padding=kernel_size+1)\n",
    "    img = conv(_sketch)\n",
    "    img = 1 - torch.min(img, torch.tensor(1))\n",
    "    img = v2.functional.resize(img, (256, 256), antialias=True)\n",
    "    images.append(img)\n",
    "\n",
    "plot_images(images, size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack multiple sketches on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 4\n",
    "overlaps = []\n",
    "for degree, image in enumerate(images[1:4][::-1]):\n",
    "    img = 1 - image\n",
    "    overlaps.append(v2.functional.rotate(img, degree))\n",
    "plot_images(1 - torch.stack(overlaps).sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpness_images = [\n",
    "    v2.functional.adjust_sharpness(images[0], 0),\n",
    "    v2.functional.adjust_sharpness(images[0], 100),\n",
    "]\n",
    "plot_images(sharpness_images, size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = v2.functional.resize(images[4], size=(64, 64), antialias=True)\n",
    "plot_images(resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_img = v2.functional.pad(images[5], padding=5, fill=1.0)\n",
    "plot_images(pad_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sketch2shape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
