{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'miner' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['miner'])`.\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n"
     ]
    }
   ],
   "source": [
    "from lib.models.siamese import Siamese\n",
    "import hydra\n",
    "from lib.utils import load_config\n",
    "\n",
    "ckpt_path = \"/home/borth/sketch2shape/logs/train/runs/2023-11-29_12-43-09/checkpoints/last.ckpt\"\n",
    "cfg = load_config(\"train_siamese\", overrides=[\"data=siamese_chair_small\",\"data.drop_last=False\"]) \n",
    "model = Siamese.load_from_checkpoint(ckpt_path)\n",
    "datamodule = hydra.utils.instantiate(cfg.data)\n",
    "# datamodule.setup(\"fit\")\n",
    "# val_dataset = datamodule.val_dataset\n",
    "# train_dataset = datamodule.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from lib.data.siamese_dataset import SiameseDatasetDynamicLoadDynamicTransform\n",
    "from lib.data.siamese_datamodule import chunk_collate_fn\n",
    "from torchvision import transforms\n",
    "\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "train_dataset = SiameseDatasetDynamicLoadDynamicTransform(\n",
    "    data_dir=cfg.data.data_dir,\n",
    "    stage=\"train\",\n",
    "    transforms=transforms,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=7,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_dataset = SiameseDatasetDynamicLoadDynamicTransform(\n",
    "    data_dir=cfg.data.data_dir,\n",
    "    stage=\"train\",\n",
    "    transforms=transforms,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,\n",
    "    num_workers=7,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'miner' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['miner'])`.\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type               | Params\n",
      "-----------------------------------------------\n",
      "0 | decoder | ResNet18           | 11.2 M\n",
      "1 | miner   | TripletMarginMiner | 0     \n",
      "2 | loss    | TripletMarginLoss  | 0     \n",
      "-----------------------------------------------\n",
      "0         Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.969    Total estimated model params size (MB)\n",
      "/home/borth/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (32) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39718bdfdcd547b49bbdd4f4be3d8bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "from pytorch_metric_learning import testers\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SiameseTester(Siamese):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # setup for inference\n",
    "        for param in self.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        d = self.decoder.resnet18.fc.out_features\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # create the indexes\n",
    "        self.train_image_index = faiss.IndexFlatL2(d)\n",
    "        self.train_sketch_index = faiss.IndexFlatL2(d)\n",
    "        self.val_image_index = faiss.IndexFlatL2(d)\n",
    "        self.val_sketch_index = faiss.IndexFlatL2(d)\n",
    "        self.test_image_index = faiss.IndexFlatL2(d)\n",
    "        self.test_sketch_index = faiss.IndexFlatL2(d)    \n",
    "\n",
    "    def combine_index(self, indexes: list):\n",
    "        vectors = []\n",
    "        for index in indexes:\n",
    "            vectors.append(self._get_all_vectors_from_faiss_index(index))\n",
    "        vectors = np.concatenate(vectors, axis=0)\n",
    "        index = faiss.IndexFlatL2(vectors.shape[0])\n",
    "        return index.add(vectors)\n",
    "\n",
    "    @property    \n",
    "    def train_image(self):\n",
    "        return self._get_all_vectors_from_faiss_index(self.train_image_index)\n",
    "\n",
    "    @property    \n",
    "    def train_sketch(self):\n",
    "        return self._get_all_vectors_from_faiss_index(self.train_sketch_index)\n",
    "\n",
    "    @property    \n",
    "    def val_image(self):\n",
    "        return self._get_all_vectors_from_faiss_index(self.val_image_index)\n",
    "\n",
    "    @property    \n",
    "    def val_sketch(self):\n",
    "        return self._get_all_vectors_from_faiss_index(self.val_sketch_index)\n",
    "\n",
    "    @property    \n",
    "    def test_image(self):\n",
    "        return self._get_all_vectors_from_faiss_index(self.test_image_index)\n",
    "\n",
    "    @property    \n",
    "    def test_sketch(self):\n",
    "        return self._get_all_vectors_from_faiss_index(self.test_sketch_index)\n",
    "\n",
    "    def _get_all_vectors_from_faiss_index(self, index):\n",
    "        num_vectors = index.ntotal\n",
    "        all_vectors = np.empty((num_vectors, index.d), dtype=np.float32)\n",
    "        batch_size = 1000\n",
    "        for start in range(0, num_vectors, batch_size):\n",
    "            end = min(start + batch_size, num_vectors)\n",
    "            vectors_batch = index.reconstruct_n(start, end - start)\n",
    "            all_vectors[start:end, :] = vectors_batch\n",
    "        return all_vectors\n",
    "\n",
    "    def _inference(self, batch):\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(batch)\n",
    "        image_emb = out[\"image_emb\"].detach().cpu().numpy()\n",
    "        sketch_emb = out[\"sketch_emb\"].detach().cpu().numpy()\n",
    "        return image_emb, sketch_emb\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image_emb, sketch_emb = self._inference(batch)\n",
    "        self.train_image_index.add(image_emb)\n",
    "        self.train_sketch_index.add(sketch_emb)\n",
    "\n",
    "    def on_training_end(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image_emb, sketch_emb = self._inference(batch)\n",
    "        self.train_image_index.add(image_emb)\n",
    "        self.train_sketch_index.add(sketch_emb)\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        image_emb, sketch_emb = self._inference(batch)\n",
    "        self.train_image_index.add(image_emb)\n",
    "        self.train_sketch_index.add(sketch_emb)\n",
    "\n",
    "    def on_test_end(self) -> None:\n",
    "        pass\n",
    "\n",
    "tester = SiameseTester.load_from_checkpoint(ckpt_path)\n",
    "trainer = Trainer(\n",
    "    max_epochs=1,\n",
    "    num_sanity_val_steps=0,\n",
    "    # limit_val_batches=0,\n",
    "    limit_test_batches=0,\n",
    ")\n",
    "trainer.fit(tester, datamodule=datamodule)\n",
    "image_index = tester.combine_index([tester.train_image_index, tester.val_image_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/borth/sketch2shape/notebooks/tester.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m image_index \u001b[39m=\u001b[39m tester\u001b[39m.\u001b[39;49mcombine_index([tester\u001b[39m.\u001b[39;49mtrain_image_index, tester\u001b[39m.\u001b[39;49mval_image_index])\n",
      "\u001b[1;32m/home/borth/sketch2shape/notebooks/tester.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m vectors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(vectors, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m index \u001b[39m=\u001b[39m faiss\u001b[39m.\u001b[39mIndexFlatL2(vectors\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mreturn\u001b[39;00m index\u001b[39m.\u001b[39;49madd(vectors)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/faiss/contrib/torch_utils.py:114\u001b[0m, in \u001b[0;36mhandle_torch_Index.<locals>.torch_replacement_add\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtorch_replacement_add\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    113\u001b[0m         \u001b[39m# forward to faiss __init__.py base method\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_numpy(x)\n\u001b[1;32m    116\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39mis\u001b[39;00m torch\u001b[39m.\u001b[39mTensor\n\u001b[1;32m    117\u001b[0m     n, d \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/faiss/class_wrappers.py:228\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_add\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Adds vectors to the index.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[39mThe index must be trained before vectors can be added to it.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39mThe vectors are implicitly numbered in sequence. When `n` vectors are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39m    `dtype` must be float32.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m n, d \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 228\u001b[0m \u001b[39massert\u001b[39;00m d \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md\n\u001b[1;32m    229\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(x, dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_c(n, swig_ptr(x))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7fba1318a600> >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.train_image_index\n",
    "tester.val_image_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/borth/sketch2shape/notebooks/tester.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m index \u001b[39m=\u001b[39m tester\u001b[39m.\u001b[39mtrain_image_index\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m index\u001b[39m.\u001b[39;49madd(tester\u001b[39m.\u001b[39;49mval_image_index)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tester\u001b[39m.\u001b[39m_get_all_vectors_from_faiss_index(index)\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/faiss/contrib/torch_utils.py:116\u001b[0m, in \u001b[0;36mhandle_torch_Index.<locals>.torch_replacement_add\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# forward to faiss __init__.py base method\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_numpy(x)\n\u001b[0;32m--> 116\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(x) \u001b[39mis\u001b[39;00m torch\u001b[39m.\u001b[39mTensor\n\u001b[1;32m    117\u001b[0m n, d \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m d \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39md\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "index = tester.train_image_index\n",
    "index.add(tester.val_image_index)\n",
    "tester._get_all_vectors_from_faiss_index(index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/borth/sketch2shape/notebooks/tester.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39m32\u001b[39m, \u001b[39m128\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btuini15-vc04.vc.in.tum.de/home/borth/sketch2shape/notebooks/tester.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m tester\u001b[39m.\u001b[39;49mimage_index\u001b[39m.\u001b[39;49msearch(x, k\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randn(32, 128)\n",
    "tester.image_index.search(x, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[114.62485 , 118.6391  , 119.15996 , 119.19931 , 119.35205 ,\n",
       "         119.6527  , 119.751816, 120.0435  , 120.20599 , 120.37848 ,\n",
       "         120.38583 , 120.54114 , 120.581345, 120.650406, 120.82707 ,\n",
       "         120.84895 , 120.90802 , 120.96532 , 120.97449 , 121.00253 ]],\n",
       "       dtype=float32),\n",
       " array([[110760,  81641, 139215,  67727, 153218,  76287, 153231, 120576,\n",
       "         127798, 101635,  94316, 112844, 149910,   1100,  19147,  17378,\n",
       "          66755,  47478,  16482, 112841]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randn(1, 128)\n",
    "tester.image_index.search(x, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precition@k\n",
    "\n",
    "# recall@k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in method 'IndexFlat_reconstruct', argument 2 of type 'faiss::idx_t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3497905/747622594.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;31m# Get the total number of vectors in the index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnum_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Specify the range of IDs covering all vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/faiss/contrib/torch_utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, x)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0musing_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetResources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# CPU torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstruct_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/faiss/swigfaiss_avx2.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, recons)\u001b[0m\n\u001b[1;32m   2026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2027\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexFlat_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: in method 'IndexFlat_reconstruct', argument 2 of type 'faiss::idx_t'"
     ]
    }
   ],
   "source": [
    "# Get the total number of vectors in the index\n",
    "num_vectors = tester.image_index.ntotal\n",
    "\n",
    "# Specify the range of IDs covering all vectors\n",
    "ids_to_retrieve = list(range(num_vectors))\n",
    "\n",
    "# Get all vectors from the index\n",
    "all_vectors = tester.image_index.reconstruct(ids_to_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<faiss.swigfaiss_avx2.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x7fe460aeda20> >"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.image_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Assuming tester.image_index is your Faiss index\n",
    "\n",
    "# Get the total number of vectors in the index\n",
    "num_vectors = tester.image_index.ntotal\n",
    "\n",
    "# Specify the range of IDs covering all vectors\n",
    "ids_to_retrieve = list(range(num_vectors))\n",
    "\n",
    "# Initialize an empty array to store all vectors\n",
    "all_vectors = np.empty((num_vectors, tester.image_index.d), dtype=np.float32)\n",
    "\n",
    "# Retrieve vectors in batches (you can adjust the batch size as needed)\n",
    "batch_size = 1000\n",
    "\n",
    "for start in range(0, num_vectors, batch_size):\n",
    "    end = min(start + batch_size, num_vectors)\n",
    "    \n",
    "    # Retrieve vectors in the current batch\n",
    "    vectors_batch = tester.image_index.reconstruct_n(start, end - start)\n",
    "    \n",
    "    # Store the vectors in the result array\n",
    "    all_vectors[start:end, :] = vectors_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_embs = get_all_vectors_from_faiss_index(tester.image_index)\n",
    "sketch_embs = get_all_vectors_from_faiss_index(tester.sketch_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tester.image_index.search(image_embs, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.5258789e-05, 3.5209999e+00, 6.1294518e+00],\n",
       "        [2.2888184e-05, 6.1474991e+00, 7.6835938e+00],\n",
       "        [0.0000000e+00, 8.3300247e+00, 1.0208111e+01],\n",
       "        ...,\n",
       "        [0.0000000e+00, 1.0393028e+01, 1.0764172e+01],\n",
       "        [0.0000000e+00, 1.0492321e+01, 1.1005440e+01],\n",
       "        [0.0000000e+00, 9.2644119e+00, 9.6041336e+00]], dtype=float32),\n",
       " array([[     0,      4,     16],\n",
       "        [     1,      3,     23],\n",
       "        [     2,     10,  43946],\n",
       "        ...,\n",
       "        [204797, 189764, 184665],\n",
       "        [204798, 204790, 204787],\n",
       "        [204799,  91167, 204791]]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
