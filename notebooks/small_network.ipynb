{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32]), 38116)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleDecoder(nn.Module):\n",
    "    def __init__(self, embedding_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 4, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, 5),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(1),\n",
    "        )\n",
    "        # calculate the dimension of the input mlp\n",
    "        x = torch.randn(1, 3, cfg.image_size, cfg.image_size)\n",
    "        flatten_dim = cnn(x).shape[-1]\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(flatten_dim, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, embedding_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x) \n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = SimpleDecoder()\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "net(x).shape, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.utils import load_config\n",
    "cfg = load_config()\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(3, 4, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(4, 8, 5),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Flatten(1),\n",
    ")\n",
    "# calculate the dimension of the input mlp\n",
    "x = torch.randn(1, 3, cfg.image_size, cfg.image_size)\n",
    "flatten_dim = cnn(x).shape[-1]\n",
    "# mlp\n",
    "# cnn(x).shape\n",
    "flatten_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 28, 28]), 456)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 32, 32)\n",
    "conv1 = nn.Conv2d(3, 6, 5)\n",
    "total_params = sum(p.numel() for p in conv1.parameters())\n",
    "conv1(x).shape, total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.utils import load_config\n",
    "from lib.data.dataset import ShapeNetDataset\n",
    "cfg = load_config()\n",
    "dataset = ShapeNetDataset(cfg=cfg)\n",
    "dataset[0]['sketch'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
