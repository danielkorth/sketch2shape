# @package _global_

defaults:
  - data:
    - optimize_latent 
  - trainer: default
  - logger: null
  - hydra: default
  - paths: default
  - debug: null
  - optional local: default
  - _self_

seed: 123
task_name: optimize_deepsdf
tags: ["optimize_deepsdf"]
train: True 
test: True
save_mesh: True

trainer:
  accelerator: gpu
  max_epochs: 100
  log_every_n_steps: 1
  num_sanity_val_steps: 0

model:
  _target_: lib.models.deepsdf.DeepSDFLatentOptimizer
  ckpt_path: ??? 
  prior_idx: -1
  reg_loss: True
  reg_weight: 1e-05
  loss:
    _target_: torch.nn.L1Loss
    _partial_: true
    reduction: mean
  optimizer:
    _target_: torch.optim.Adam
    _partial_: true
    lr: 1e-02
  scheduler:
    _partial_: True
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 100
    gamma: 0.5

data:
  train_dataset:
    _target_: lib.data.deepsdf_dataset.DeepSDFLatentOptimizerDataset
    subsample: 16384
    half: False
