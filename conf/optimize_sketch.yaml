# @package _global_

defaults:
  - data: optimize_latent
  - dataset: shapenet_chair_4096 
  - model: optimize_latent
  - trainer: default
  - logger: wandb
  - hydra: default
  - paths: default
  - debug: null
  - optional local: default
  - _self_

seed: 123
task_name: optimize_sketch
tags: ["optimize_sketch"]
split: test # train, train_latent, val, val_latent, test
obj_ids: ???  # overrids the split setting, make sure that obj_ids are only from the same split.
obj_dir: ???
train: True
eval: True 
save_mesh: True
save_latent: True
create_video: False 
deepsdf_ckpt_path: ${paths.checkpoint_dir}/deepsdf.ckpt
loss_ckpt_path: ${paths.checkpoint_dir}/latent_traverse.ckpt
mode: 9  # 10
view_id: 6  # 0

trainer:
  num_sanity_val_steps: 0
  reload_dataloaders_every_n_epochs: False 
  max_epochs: 5
  accumulate_grad_batches: 12

data:
  num_workers: 0
  pin_memory: False
  persistent_workers: False
  size: 256
  milestones: []
  dataset:
    _target_: lib.data.dataset.optimize_latent.SketchLatentOptimizerDataset
    # azims: [45] 
    # elevs: [-20]
    # azims: [90, 45, 0, -45, -90]
    # elevs: [-20]
    azims: [80, 50, 30, -10, -40, -60]
    elevs: [-45, -15]
    mode: ${mode}
    view_id: ${view_id}
  shuffle: True

model:
  # custom settings
  _target_: lib.optimizer.sketch.SketchOptimizer
  loss_mode: l1
  loss_weight: 5e-03
  silhouette_loss: silhouette
  silhouette_weight: 1.0
  reg_loss: latent
  reg_weight: 3e-02
  # base settings
  optimizer:
    lr: 5e-03
  scheduler: null
  latent_init: latent
  capture_rate: 12
  prior_mode: ${mode}
  prior_view_id: ${view_id}