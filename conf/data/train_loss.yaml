# @package data

_target_: lib.data.datamodule.loss.LossDataModule
# settings
data_dir: ${paths.data_dir}/${data.dataset_name}
train_modes: [0, 2]
eval_modes: [0, 2]
latent: False
# training
batch_size: 256
num_workers: 7
pin_memory: True
drop_last: True
shuffle: False
persistent_workers: True
# dataset 
train_sampler:
  _target_: lib.data.sampler.ChunkSampler 
  _partial_: True
  chunk_size: 2
  sample_steps: -1
eval_sampler:
  _target_: lib.data.sampler.ChunkSampler 
  _partial_: True
  chunk_size: 2
  sample_steps: -1  # full dataset
dataset: 
  _target_: lib.data.dataset.loss.LossDataset
  _partial_: True
  sketch_transform:
    _target_: lib.data.transforms.BaseTransform
    mean: 0.5
    std: 0.5
    transforms:
      - _target_: torchvision.transforms.v2.Resize
        size: [256, 256]
      - _target_: torchvision.transforms.v2.RandomRotation
        degrees: 5 
        fill: 1.0
      - _target_: torchvision.transforms.v2.RandomChoice
        transforms:
          - _target_: lib.data.transforms.DilateSketch
            kernel_size: 1
          - _target_: lib.data.transforms.DilateSketch
            kernel_size: 3
          - _target_: lib.data.transforms.DilateSketch
            kernel_size: 5
          - _target_: lib.data.transforms.DilateSketch
            kernel_size: 7
          - _target_: lib.data.transforms.DilateSketch
            kernel_size: 9
      - _target_: torchvision.transforms.v2.RandomHorizontalFlip
  image_transform:
    _target_: lib.data.transforms.BaseTransform
    mean: 0.5
    std: 0.5
    transforms:
      - _target_: torchvision.transforms.v2.Resize
        size: [256, 256]
      - _target_: torchvision.transforms.v2.RandomHorizontalFlip
