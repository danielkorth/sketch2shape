# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: siamese_chair_large
  - override /model: siamese
  - override /callbacks: default
  - override /trainer: default
  - override /logger: wandb

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["siamese", "chair_large", "save"]

trainer:
  accelerator: gpu
  max_epochs: 3
  profiler:
    _target_: lightning.pytorch.profilers.SimpleProfiler 
    dirpath: ${paths.output_dir}/profiler
    filename: simple_profiler
  val_check_interval: 100


data:
  batch_size: 4
  num_workers: 4
  pin_memory: True 
  drop_last: True
  persistent_workers: True
  sampler: null
  # dataset:
  #   _target_: lib.data.siamese_dataset.SiameseDatasetDynamicLoadDynamicTransform
  # collate_fn: null
  dataset:
    _target_: lib.data.siamese_dataset.SiameseChunkDataset
  # dataset:
  #   _target_: lib.data.siamese_dataset.SiameseH5pyDataset
  collate_fn:
    _target_: lib.data.siamese_datamodule.chunk_collate_fn
    _partial_: True

model:
  scheduler: null
  optimizer:
    lr: 1e-04
  decoder:
    _target_: lib.models.layers.ResNet18
    embedding_size: 32
  miner:
    margin: 0.05
  loss:
    margin: 0.05
    reducer: 
      _target_: pytorch_metric_learning.reducers.MeanReducer
    # embedding_regularizer:
    #   _target_: pytorch_metric_learning.regularizers.LpRegularizer
    #   p: 2
    #   power: 1

logger:
  wandb:
    tags: ${tags}
    group: "siamese"

# logger: null