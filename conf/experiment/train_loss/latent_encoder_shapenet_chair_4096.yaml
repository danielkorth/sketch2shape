# @package _global_

defaults:
  - override /data:
    - train_latent_encoder
    - eval_siamese
  - override /dataset: shapenet_chair_4096
  - override /logger: wandb
  - override /model: latent_encoder 

task_name: train_latent_encoder
tags: ["train_latent_encoder", "shapenet_chair_4096"]
deepsdf_ckpt_path: ${paths.checkpoint_dir}/deepsdf.ckpt

trainer:
  max_epochs: 100
  check_val_every_n_epoch: 1

model:
  lr_head: 1e-03
  lr_backbone: 1e-04
  embedding_size: 256
  scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    _partial_: True
    step_size: 100
    gamma: 0.5

data:
  batch_size: 256
  train_sampler:
    chunk_size: 2
    sample_steps: 10
  
callbacks:
  model_checkpoint:
    save_top_k: -1
    every_n_epochs: 10
    save_last: True
  early_stopping:
    monitor: val/loss
    patience: 100
